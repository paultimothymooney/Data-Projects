# Next I will do some feature selection

# How many features should I eliminate?

import matplotlib.pyplot as plt
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.feature_selection import RFECV
from sklearn.datasets import make_classification

def determineOptimalFeatureNumber(a,b):
    """
    #http://scikit-learn.org/stable/auto_examples/feature_selection/plot_rfe_with_cross_validation.html
    """
    models = []
    models.append(('LR', LogisticRegression()))
    models.append(('RF', RandomForestClassifier()))
    #models.append(('KNN', KNeighborsClassifier()))
    #models.append(('SVM', SVC()))
    models.append(('LSVM', LinearSVC()))
    #models.append(('GNB', GaussianNB()))
    models.append(('DTC', DecisionTreeClassifier()))
    models.append(('GBC', GradientBoostingClassifier()))
    #models.append(('LDA', LinearDiscriminantAnalysis()))
    
    for name, model in models:
        # Create the RFE object and compute a cross-validated score.
        currentModel = model
        # The "accuracy" scoring is proportional to the number of correct
        # classifications
        rfecv = RFECV(estimator=currentModel, step=1, cv=StratifiedKFold(2), scoring='accuracy')
        rfecv.fit(a,b)
        print("Optimal number of features : %d" % rfecv.n_features_)
        # Plot number of features VS. cross-validation scores
        plt.figure()
        plt.xlabel("Number of features selected for %s" % (name))
        plt.ylabel("Cross validation score (nb of correct classifications)")
        plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)
        plt.show()

determineOptimalFeatureNumber(X_train, Y_train)

######
######

# Now we will eliminate all but the most helpful features
# We will do this by fitting a LinearSVC and then identifying the best coefficients
#from sklearn.model_selection import GridSearchCV
#from sklearn.metrics import make_scorer, accuracy_score
  
#Run LinearSVC
def runLinearSVC(a,b,c,d):
    """Run LinearSVC w/ Kfold CV"""
    model = LinearSVC()
    model.fit(a,b)
    kfold = model_selection.KFold(n_splits=10)
    accuracy = model_selection.cross_val_score(model, c,d, cv=kfold, scoring='accuracy')
    mean = accuracy.mean() 
    stdev = accuracy.std()
    print('LinearSVC - Training set accuracy: %s (%s)' % (mean, stdev))
    print('')
runLinearSVC(X_train, Y_train, X_test, Y_test)


# Identify best feature coefficients (coef_) and/or feature importance (feature_importances_)
model = LinearSVC()
model.fit(X_train,Y_train) # Needed to initialize coef_
columns = X_train.columns
coefficients = model.coef_.reshape(X_train.columns.shape[0], 1)
absCoefficients = abs(coefficients)
fullList = pd.concat((pd.DataFrame(columns, columns = ['Variable']), pd.DataFrame(absCoefficients, columns = ['absCoefficient'])), axis = 1).sort_values(by='absCoefficient', ascending = False)
print('LinearSVC - Feature Importance:')
print('')
print(fullList)
print('')
# Remove all but the most helpful features
### Note that if I was worried about overfitting the training data I would eliminate a lot of features
### Right now I am not too worried about overfitting and would rather retain as much information as possible since it is all very relevant.
### As such I will limit us to 50 features, which ends up not eliminating any features at all.
topTwenty = fullList[:50]
featureList = topTwenty.values
featureList = pd.DataFrame(featureList)
featuresOnly = featureList[0]
featuresOnly = list(featuresOnly)
featuresOnly += ['diagnosis']
trainingDataDummies = trainingDataDummies[featuresOnly]
#g = sns.heatmap(trainingData[featuresOnly].corr(),cmap="BrBG",annot=False)

# Let's see if we improved our accuracy scores

# Split up the training data, setting aside 20%
# of the training data for cross-validation testing,
#X = trainingData.iloc[0:5000,1:] 
#y = trainingData.iloc[0:5000,:1] 
xValues = trainingDataDummies.drop(['diagnosis'], axis=1)
yValues = trainingDataDummies['diagnosis']
#yValues = y
# Here comes the important part
X_train, X_test, Y_train, Y_test = train_test_split(xValues, yValues, test_size=0.2)
# The train_test_split function is important for cross-validation
# Learn more about this important concept at the following links:
#http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html
#http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation

print('')
print('Dataset reduced to the following columns:')
print('')
print(X_train.columns)

########
#######

{
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": null,
      "source": [
        "#\n",
        "#This Python 3 script takes as an input the CSV file from the Kaggle Breast Cancer Wisconsin Dataset (https://www.kaggle.com/uciml/breast-cancer-wisconsin-data)\n",
        "#This CSV file contains information on various features describing the size and shape of the nucleus.\n",
        "#The measurements were made from digital images of a fine needle aspirate of a breast tissue mass.\n",
        "#This output of this script is a prediction of whether a given sample is benign or malignant.\n",
        "#\n",
        "# Paul Mooney, October 2017\n",
        "\n",
        "# Part One: 90% Accuracy with a Minimal Dataset\n",
        "# Part Two: 95% Accuracy with the Full Dataset\n",
        "\n",
        "# Jupyter Notebook: https://www.kaggle.com/paultimothymooney/predict-cancer-pandas-matplotlib-sklearn/\n",
        "\n",
        "\n",
        "\n",
        "# The nucleus is an organelle present within all eukaryotic cells, including human cells.\n",
        "# Abberant nuclear shape can be used to identify cancer cells (e.g. pap smear tests and the diagnosis of cervical cancer).\n",
        "# Likewise, a growing body of literature suggests that there is some connection \n",
        "# between the shape of the nucleus and human disease states such as cancer and aging.\n",
        "# As such, the quantitative analysis of nuclear size of shape has important biomedical applications.\n",
        "\n",
        "\n",
        "# For more information, please refer to the following resources:\n",
        "# http://www.uwyo.edu/levy_lab/\n",
        "# Vukovic LD, Jevtic P, Edens LJ, Levy DL. (2016) New Insights into Mechanisms and Functions of Nuclear Size Regulation. Int Rev Cell Mol Biol. 322:1–59.\n",
        "# Webster, M., Witkin, K.L., and Cohen-Fix, O. (2009). Sizing up the nucleus: nuclear shape, size and nuclear-envelope assembly. J. Cell Sci. 122, 1477–1486.\n",
        "# Zink, D., Fischer, A.H., and Nickerson, J.A. (2004). Nuclear structure in cancer cells. Nat. Rev. Cancer 4, 677–687.\n",
        "\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "15a312ba-1a67-483f-8819-2fd6f96fdba2",
        "_uuid": "215298533ff1339de4caf96bf451438a06150883",
        "collapsed": true
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "\n",
        "#################\n",
        "#################\n",
        "# Part One: 90% Accuracy with a Minimal Dataset\n",
        "#################\n",
        "#################\n",
        "\n",
        "\n",
        "\n",
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "# Next I need to set my current working directory to the folder that contains the relevant CSV files.\n",
        "# These data files were downloaded from https://www.kaggle.com/uciml/breast-cancer-wisconsin-data.\n",
        "import os\n",
        "#os.chdir('/Users/ptm/desktop/Current_working_directory')\n",
        "# We will begin by loading the relevant data.\n",
        "#trainingData = pd.read_csv('data.csv')\n",
        "trainingData = pd.read_csv('../input/data.csv')\n",
        "\n",
        "# Next we will inspect the data.  We will print the names of each column.\n",
        "\n",
        "def printColumnTitles(input):\n",
        "    \"\"\" \n",
        "    This function takes as an input a dataframe containing columns.  \n",
        "    The output is the name of each column;\n",
        "    \"\"\"  \n",
        "    \n",
        "    print('')\n",
        "    print('Column Values:')\n",
        "    print('')\n",
        "    print(input.columns.values)\n",
        "    print('')\n",
        "    return\n",
        "printColumnTitles(trainingData)\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "4fba0565-4e7d-4fcb-9419-521b8da6e39a",
        "_uuid": "cecb085433a4e7e98861ec5018550481a5977b8a"
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "# Some of these columns are redundant.  For the sake of simplicity, I am going to delete most of the columns.  Don't worry, I'lll add them back later.\n",
        "\n",
        "\n",
        "trainingData = trainingData.drop(['id', 'radius_mean', 'perimeter_mean',\n",
        " 'compactness_mean', 'fractal_dimension_mean', 'radius_se',\n",
        " 'texture_se', 'perimeter_se', 'smoothness_se', 'compactness_se',\n",
        " 'concavity_se', 'concave points_se', 'fractal_dimension_se',\n",
        " 'radius_worst', 'texture_worst', 'perimeter_worst',\n",
        " 'smoothness_worst', 'compactness_worst', 'concavity_worst',\n",
        " 'concave points_worst', 'fractal_dimension_worst', 'Unnamed: 32', 'area_se', 'symmetry_se',\n",
        " 'area_worst', 'symmetry_worst', 'concavity_mean'], axis=1)\n",
        "\n",
        "    \n",
        "\n",
        "# These are the new column values after simplification.    \n",
        "    \n",
        "\n",
        "def describeDataAgain(input):\n",
        "    \"\"\" \n",
        "    The output of this function is a description of the dataframe input.\n",
        "    \"\"\" \n",
        "    \n",
        "    print('')\n",
        "    print('New summary of data after making changes:')\n",
        "    print('')\n",
        "    print('Column Values:')\n",
        "    print('')\n",
        "    print(input.columns.values)\n",
        "    print('')\n",
        "    print('First Few Values:')\n",
        "    print('')\n",
        "    print(input.head())\n",
        "    print('')\n",
        "    print('Null Value Counts:')\n",
        "    print('')\n",
        "    print(input.isnull().sum())\n",
        "    return\n",
        "\n",
        "describeDataAgain(trainingData)\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "8e08f832-2a8a-4239-a7e1-73da07cd9777",
        "_uuid": "6c09805b471c3a378cd629587b08069cd6ed2932"
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "\n",
        "# Now let's plot some of that data.  I want to know if the nuclei from the malignant\n",
        "# samples were larger than the nuclei from the benign samples.\n",
        "\n",
        "\n",
        "  \n",
        "def plotSizeDistribution(input):\n",
        "    \"\"\" \n",
        "    Plot size distribution\n",
        "    \"\"\"  \n",
        "    sns.set_style(\"whitegrid\")\n",
        "    distributionOne = sns.FacetGrid(input, hue=\"diagnosis\",aspect=2)\n",
        "    distributionOne.map(plt.hist, 'area_mean', bins=30)\n",
        "    distributionOne.add_legend()\n",
        "    distributionOne.set_axis_labels('area_mean', 'Count')\n",
        "    distributionOne.fig.suptitle('Area vs Diagnosis ((Blue = Malignant; Green = Benign)')\n",
        "    distributionTwo = sns.FacetGrid(input, hue=\"diagnosis\",aspect=2)\n",
        "    distributionTwo.map(sns.kdeplot,'area_mean',shade= True)\n",
        "    distributionTwo.set(xlim=(0, input['area_mean'].max()))\n",
        "    distributionTwo.add_legend()\n",
        "    distributionTwo.set_axis_labels('area_mean', 'Proportion')\n",
        "    distributionTwo.fig.suptitle('Area vs Diagnosis (Blue = Malignant; Green = Benign)')\n",
        "\n",
        "    return\n",
        "\n",
        "plotSizeDistribution(trainingData)\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "c4dc8128-ee02-42ae-8689-447b0644ded1",
        "_uuid": "a046ac1aad519bf1606cd786baed8bd865f6f0a4"
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "\n",
        "# This confirms my prediction that healthy nuclei have a default size\n",
        "# and that cancer cells have a wide range of sizes, typically greater than the default size.\n",
        "# Let's look at all of the features now.\n",
        "\n",
        "  \n",
        "def plotConcaveDistribution(input):\n",
        "    \"\"\" \n",
        "    Plot concave distribution\n",
        "    \"\"\"  \n",
        "    sns.set_style(\"whitegrid\")\n",
        "    distributionOne = sns.FacetGrid(input, hue=\"diagnosis\",aspect=2)\n",
        "    distributionOne.map(plt.hist, 'concave points_mean', bins=30)\n",
        "    distributionOne.add_legend()\n",
        "    distributionOne.set_axis_labels('concave points_mean', 'Count')\n",
        "    distributionOne.fig.suptitle('# of Concave Points vs Diagnosis (Blue = Malignant; Green = Benign)')\n",
        "    distributionTwo = sns.FacetGrid(input, hue=\"diagnosis\",aspect=2)\n",
        "    distributionTwo.map(sns.kdeplot,'concave points_mean',shade= True)\n",
        "    distributionTwo.set(xlim=(0, input['concave points_mean'].max()))\n",
        "    distributionTwo.add_legend()\n",
        "    distributionTwo.set_axis_labels('concave points_mean', 'Proportion')\n",
        "    distributionTwo.fig.suptitle('# of Concave Points vs Diagnosis (Blue = Malignant; Green = Benign)')\n",
        "\n",
        "    return\n",
        "\n",
        "plotConcaveDistribution(trainingData)\n",
        "\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "53dbe78a-7efc-4e8d-b735-a2ff72db6767",
        "_uuid": "0489c0c3411b20e2c98b6937a57d9aa0f2f4dbc4"
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "def plotSymmetryDistribution(input):\n",
        "    \"\"\" \n",
        "    plot symmetry distribution\n",
        "    \"\"\"  \n",
        "    sns.set_style(\"whitegrid\")\n",
        "    distributionOne = sns.FacetGrid(input, hue=\"diagnosis\",aspect=2)\n",
        "    distributionOne.map(plt.hist, 'symmetry_mean', bins=30)\n",
        "    distributionOne.add_legend()\n",
        "    distributionOne.set_axis_labels('symmetry_mean', 'Count')\n",
        "    distributionOne.fig.suptitle('Symmetry vs Diagnosis (Blue = Malignant; Green = Benign)')\n",
        "    distributionTwo = sns.FacetGrid(input, hue=\"diagnosis\",aspect=2)\n",
        "    distributionTwo.map(sns.kdeplot,'symmetry_mean',shade= True)\n",
        "    distributionTwo.set(xlim=(0, input['symmetry_mean'].max()))\n",
        "    distributionTwo.add_legend()\n",
        "    distributionTwo.set_axis_labels('symmetry_mean', 'Proportion')\n",
        "    distributionTwo.fig.suptitle('Symmetry vs Diagnosis (Blue = Malignant; Green = Benign)')\n",
        "\n",
        "    return\n",
        "\n",
        "plotSymmetryDistribution(trainingData)\n",
        "\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "d093080e-79f3-4f4c-ad5d-829eca723002",
        "_uuid": "f9ae46468e970890ca5a720c0474877ccfed1671"
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "def plotTextureDistribution(input):\n",
        "    \"\"\" \n",
        "    plot texture distribution\n",
        "    \"\"\"  \n",
        "    sns.set_style(\"whitegrid\")\n",
        "    distributionOne = sns.FacetGrid(input, hue=\"diagnosis\",aspect=2)\n",
        "    distributionOne.map(plt.hist, 'texture_mean', bins=30)\n",
        "    distributionOne.add_legend()\n",
        "    distributionOne.set_axis_labels('texture_mean', 'Count')\n",
        "    distributionOne.fig.suptitle('Texture vs Diagnosis (Blue = Benign; Green = Malignant)')\n",
        "    distributionTwo = sns.FacetGrid(input, hue=\"diagnosis\",aspect=2)\n",
        "    distributionTwo.map(sns.kdeplot,'texture_mean',shade= True)\n",
        "    distributionTwo.set(xlim=(0, input['texture_mean'].max()))\n",
        "    distributionTwo.add_legend()\n",
        "    distributionTwo.set_axis_labels('texture_mean', 'Proportion')\n",
        "    distributionTwo.fig.suptitle('Texture vs Diagnosis (Blue = Benign; Green = Malignant)')\n",
        "\n",
        "    return\n",
        "\n",
        "plotTextureDistribution(trainingData)\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "c95f2c44-4ef2-4c3e-99b9-fb6699a7fa4f",
        "_uuid": "cd498a5b5051b00ca0d512e9355e7fc2169337f1"
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "def plotSmoothnessDistribution(input):\n",
        "    \"\"\" \n",
        "    plot smoothness distribution\n",
        "    \"\"\"  \n",
        "    sns.set_style(\"whitegrid\")\n",
        "    distributionOne = sns.FacetGrid(input, hue=\"diagnosis\",aspect=2)\n",
        "    distributionOne.map(plt.hist, 'smoothness_mean', bins=30)\n",
        "    distributionOne.add_legend()\n",
        "    distributionOne.set_axis_labels('smoothness_mean', 'Count')\n",
        "    distributionOne.fig.suptitle('Smoothness vs Diagnosis (Blue = Benign; Green = Malignant)')\n",
        "    distributionTwo = sns.FacetGrid(input, hue=\"diagnosis\",aspect=2)\n",
        "    distributionTwo.map(sns.kdeplot,'smoothness_mean',shade= True)\n",
        "    distributionTwo.set(xlim=(0, input['smoothness_mean'].max()))\n",
        "    distributionTwo.add_legend()\n",
        "    distributionTwo.set_axis_labels('smoothness_mean', 'Proportion')\n",
        "    distributionTwo.fig.suptitle('Smoothness vs Diagnosis (Blue = Benign; Green = Malignant)')\n",
        "\n",
        "    return\n",
        "\n",
        "plotSmoothnessDistribution(trainingData)\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "f7883fb6-e8cd-4db6-bb94-4236e7d7ed9a",
        "_uuid": "96f56665528253d3acd393dc48b528298e684ccd"
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "# Next I will convert the categorical data to numerical form.\n",
        "\n",
        "def diagnosisToBinary(input):\n",
        "    \"\"\" \n",
        "    convert diagnosis to binary label\n",
        "    \"\"\" \n",
        "    input[\"diagnosis\"] = input[\"diagnosis\"].astype(\"category\")\n",
        "    input[\"diagnosis\"].cat.categories = [0,1]\n",
        "    input[\"diagnosis\"] = input[\"diagnosis\"].astype(\"int\")\n",
        "    return\n",
        "\n",
        "diagnosisToBinary(trainingData)    \n",
        "    \n",
        "\n",
        "# Next, I want to convert all continuous numerical data into values between 1 and 5\n",
        "# Note that I decided where to begin each bin (categories 0 to 5) based on the previous distributions that we just plotted.\n",
        "# By using values that are scaled between 1 and 5, it will help our classification algorithms.\n",
        "\n",
        "def areaToCategory(input):\n",
        "    \"\"\"   \n",
        "    The output is a modified dataframe where the area measurements are replaced with numbers between \n",
        "    zero and five based on their position within predetermined bins.\n",
        "    \"\"\" \n",
        "    \n",
        "    input['area_mean'] = input.area_mean.fillna(-0.5)\n",
        "    bins = (-0.01, 250, 750, 1250, 2000, 10000)\n",
        "    categories = pd.cut(input.area_mean, bins, labels=False)\n",
        "    input.area_mean = categories\n",
        "    return\n",
        "\n",
        "areaToCategory(trainingData)\n",
        "\n",
        "\n",
        "\n",
        "def concaveToCategory(input):\n",
        "    \"\"\"  \n",
        "    The output is a modified dataframe where the shape measurements are replaced with numbers between \n",
        "    zero and five based on their position within predetermined bins.\n",
        "    \"\"\" \n",
        "    # Get rid of the space in the file name\n",
        "    cols = trainingData.columns\n",
        "    cols = cols.map(lambda x: x.replace(' ', '_') if isinstance(x, (str, bytes)) else x)\n",
        "    trainingData.columns = cols\n",
        "    # Run the function\n",
        "    input['concave_points_mean'] = input.concave_points_mean.fillna(-0.5)\n",
        "    bins = (-0.01, 0.03, 0.06, 0.1, 1.0)\n",
        "    categories = pd.cut(input.concave_points_mean, bins, labels=False)\n",
        "    input.concave_points_mean = categories\n",
        "    return\n",
        "\n",
        "concaveToCategory(trainingData)\n",
        "\n",
        "\n",
        "def symmetryToCategory(input):\n",
        "    \"\"\" \n",
        "    The output is a modified dataframe where the shape measurements are replaced with numbers between \n",
        "    zero and five based on their position within predetermined bins.\n",
        "    \"\"\" \n",
        "    \n",
        "    input['symmetry_mean'] = input.symmetry_mean.fillna(-0.5)\n",
        "    bins = (-0.01, 0.15, 0.17, 0.2, 1.0)\n",
        "    categories = pd.cut(input.symmetry_mean, bins, labels=False)\n",
        "    input.symmetry_mean = categories\n",
        "    return\n",
        "\n",
        "symmetryToCategory(trainingData)\n",
        "\n",
        "\n",
        "def textureToCategory(input):\n",
        "    \"\"\" \n",
        "    The output is a modified dataframe where the shape measurements are replaced with numbers between \n",
        "    zero and five based on their position within predetermined bins.\n",
        "    \"\"\" \n",
        "    \n",
        "    input['texture_mean'] = input.texture_mean.fillna(-0.5)\n",
        "    bins = (-0.01, 10, 15, 19, 25, 100)\n",
        "    categories = pd.cut(input.texture_mean, bins, labels=False)\n",
        "    input.texture_mean = categories\n",
        "    return\n",
        "\n",
        "textureToCategory(trainingData)\n",
        "\n",
        "def smoothnessToCategory(input):\n",
        "    \"\"\" \n",
        "    The output is a modified dataframe where the shape measurements are replaced with numbers between \n",
        "    zero and five based on their position within predetermined bins.\n",
        "    \"\"\" \n",
        "    \n",
        "    input['smoothness_mean'] = input.smoothness_mean.fillna(-0.5)\n",
        "    bins = (-0.01, 0.07, 0.09, 0.11, .13, 1)\n",
        "    categories = pd.cut(input.smoothness_mean, bins, labels=False)\n",
        "    input.smoothness_mean = categories\n",
        "    return\n",
        "\n",
        "smoothnessToCategory(trainingData)\n",
        "\n",
        "# Now this is what our new data looks like:\n",
        "\n",
        "describeDataAgain(trainingData)\n",
        "\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "644ef1e4-0f06-4e15-9ba3-cf333a3af99d",
        "_uuid": "fe1996e6c00b1c79513ea7995bdb90ea4f1776c4"
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "\n",
        "# Now I will look at all of the variables together, using a heatmap.\n",
        "\n",
        "\n",
        "def makeAHeatMap(input):\n",
        "    \"\"\" \n",
        "    The output is a heatmap showing the relationship between each numerical feature; \n",
        "    \"\"\"  \n",
        "    \n",
        "    plt.figure(figsize=[8,6])\n",
        "    heatmap = sns.heatmap(input.corr(), vmax=1.0, square=True, annot=True)\n",
        "    heatmap.set_title('Pearson Correlation Coefficients')\n",
        "\n",
        "    return\n",
        "    \n",
        "makeAHeatMap(trainingData)\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "faf52264-a7af-4fe4-ad9d-c2f9182dac71",
        "_uuid": "01cdac937441a590a985a32a749cd62d40979a74"
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "# Here with this heatmap we can see that big, mis-shapen nuclei are typicaly from cancerous samples.\n",
        "# Let's explore that in more detail.\n",
        "\n",
        "\n",
        "\n",
        "def pivotTheData(input):\n",
        "    \"\"\" \n",
        "    The output is a couple of pivot tables showing the relationship between these selected features.\n",
        "    \"\"\"    \n",
        "    \n",
        "    print('')\n",
        "    print('Pivot Tables:')\n",
        "    print('')\n",
        "    print(input[[\"area_mean\", \"diagnosis\"]].groupby(['area_mean'], as_index=False).mean().sort_values(by='diagnosis', ascending=False))\n",
        "    print('')\n",
        "    print(input[[\"concave_points_mean\", \"diagnosis\"]].groupby(['concave_points_mean'], as_index=False).mean().sort_values(by='diagnosis', ascending=False))\n",
        "    print('')\n",
        "    print(input[['symmetry_mean', 'diagnosis']].groupby(['symmetry_mean'], as_index=False).mean().sort_values(by='diagnosis', ascending=False))\n",
        "    print('')\n",
        "    print(input[['texture_mean', 'diagnosis']].groupby(['texture_mean'], as_index=False).mean().sort_values(by='diagnosis', ascending=False))\n",
        "    print('')\n",
        "    print(input[['smoothness_mean', 'diagnosis']].groupby(['smoothness_mean'], as_index=False).mean().sort_values(by='diagnosis', ascending=False))\n",
        "    print('')\n",
        "    return\n",
        "\n",
        "pivotTheData(trainingData)\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "e760048a-de3e-4fd3-a8d1-e593ea30b357",
        "_uuid": "7c2b57cc153f45b3a54f845d86f3debaa60ac1fe"
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "def plotTheData(input):\n",
        "    \"\"\" \n",
        "    The output is a bunch of bar graphs illustrating the relationships between certain features.\n",
        "    \"\"\"  \n",
        "    \n",
        "    fig = plt.figure(figsize=[10,8])\n",
        "    fig.subplots_adjust(hspace=1.0)\n",
        "    plt.subplot(321)\n",
        "    plotOne = sns.barplot('area_mean', 'diagnosis', data=input, capsize=.1, linewidth=2.5, facecolor=(1, 1, 1, 0), errcolor=\".2\", edgecolor=\".2\")\n",
        "    plotOne.set_title('Diagnosis vs Area')\n",
        "    plotOne.set(xlabel='Average Surface Area (0 = smallest nuclei, 4 = largest nuclei)', ylabel='Probability of Malignant Diagnosis')\n",
        "    plt.subplot(322)\n",
        "    plotTwo = sns.barplot('concave_points_mean', 'diagnosis', data=input, capsize=.1, linewidth=2.5, facecolor=(1, 1, 1, 0), errcolor=\".2\", edgecolor=\".2\")\n",
        "    plotTwo.set_title('Diagnosis vs # Concave Points \\n (0 = least points, 3 = most points)')\n",
        "    plt.subplot(323)\n",
        "    plotTwo = sns.barplot('texture_mean', 'diagnosis', data=input, capsize=.1, linewidth=2.5, facecolor=(1, 1, 1, 0), errcolor=\".2\", edgecolor=\".2\")\n",
        "    plotTwo.set_title('Diagnosis vs Texture \\n (0 = low gray value stdev, 4 = high gray value stdev)')\n",
        "    plt.subplot(324)\n",
        "    plotTwo = sns.barplot('symmetry_mean', 'diagnosis', data=input, capsize=.1, linewidth=2.5, facecolor=(1, 1, 1, 0), errcolor=\".2\", edgecolor=\".2\")\n",
        "    plotTwo.set_title('Diagnosis vs Symmetry \\n (0 = low symmetry score, 3 = high symmetry score))') \n",
        "    plt.subplot(325)\n",
        "    plotTwo = sns.barplot('smoothness_mean', 'diagnosis', data=input, capsize=.1, linewidth=2.5, facecolor=(1, 1, 1, 0), errcolor=\".2\", edgecolor=\".2\")\n",
        "    plotTwo.set_title('Diagnosis vs Smoothness \\n (0 = low variation in radius lengths, 0 = high variation in radius lengths)') \n",
        "plotTheData(trainingData)\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "027dd586-40f1-4ea9-bfc3-58b7bdfcce77",
        "_uuid": "7ac309176369ca01b111f009afd6a9169a9c83fa"
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "# Great!  This means that our classification algorithms should have something\n",
        "# good to work with.  Next we will identify a suitable classification algorithm\n",
        "# that we can use to predict whether or not a given sample is malignant.\n",
        "\n",
        "\n",
        "\n",
        "# To do this, we will import some additional Python libraries that contain\n",
        "# methods and algorithms that are helpful for machine learning applications.\n",
        "\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "#from sklearn.metrics import make_scorer, accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "\n",
        "\n",
        "# We will need to split up our training data, setting aside 20%\n",
        "# of the training data for cross-validation testing, such that we can avoid\n",
        "# potentially overfitting the data.\n",
        "X_train = 0\n",
        "X_test = 0\n",
        "Y_train = 0\n",
        "Y_test = 0\n",
        "xValues = trainingData.drop(['diagnosis'], axis=1)\n",
        "yValues = trainingData['diagnosis']\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(xValues, yValues, test_size=0.2, random_state=23)\n",
        "# The train_test_split function is important for cross-validation\n",
        "# Learn more about this important concept at the following links:\n",
        "#http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "#http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "6d3021a0-6ad0-4604-918d-74fa43ff601d",
        "_uuid": "a34a3cc3310ffd10454e3d4044bb8e96a225925e",
        "collapsed": true
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "# There are a lot of different classification algorithms to choose between.\n",
        "# Let's compare nine of them.\n",
        "\n",
        "\n",
        "\n",
        "def compareABunchOfDifferentModelsAccuracy(a, b, c, d):\n",
        "    \"\"\"\n",
        "    compare performance of classifiers on X_train, X_test, Y_train, Y_test\n",
        "    http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score\n",
        "    http://scikit-learn.org/stable/modules/model_evaluation.html#accuracy-score\n",
        "    \"\"\"    \n",
        "    print('')\n",
        "    print('Compare Multiple Classifiers:')\n",
        "    print('')\n",
        "    print('K-Fold Cross-Validation Accuracy:')\n",
        "    print('')\n",
        "    models = []\n",
        "    models.append(('LR', LogisticRegression()))\n",
        "    models.append(('RF', RandomForestClassifier()))\n",
        "    models.append(('KNN', KNeighborsClassifier()))\n",
        "    models.append(('SVM', SVC()))\n",
        "    models.append(('LSVM', LinearSVC()))\n",
        "    models.append(('GNB', GaussianNB()))\n",
        "    models.append(('DTC', DecisionTreeClassifier()))\n",
        "    models.append(('GBC', GradientBoostingClassifier()))\n",
        "    #models.append(('LDA', LinearDiscriminantAnalysis()))\n",
        "        \n",
        "    resultsAccuracy = []\n",
        "    names = []\n",
        "    for name, model in models:\n",
        "        model.fit(a, b)\n",
        "        kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
        "        accuracy_results = model_selection.cross_val_score(model, c, d, cv=kfold, scoring='accuracy')\n",
        "        resultsAccuracy.append(accuracy_results)\n",
        "        names.append(name)\n",
        "        accuracyMessage = \"%s: %f (%f)\" % (name, accuracy_results.mean(), accuracy_results.std())\n",
        "        print(accuracyMessage)\n",
        "\n",
        "    \n",
        "    # boxplot algorithm comparison\n",
        "    fig = plt.figure()\n",
        "    fig.suptitle('Algorithm Comparison: Accuracy')\n",
        "    ax = fig.add_subplot(111)\n",
        "    plt.boxplot(resultsAccuracy)\n",
        "    ax.set_xticklabels(names)\n",
        "    ax.set_ylabel('Cross-Validation: Accuracy Score')\n",
        "    plt.show()\n",
        "    return\n",
        "\n",
        "\n",
        "compareABunchOfDifferentModelsAccuracy(X_train, Y_train, X_test, Y_test)\n",
        "\n",
        "\n",
        "def defineModels():\n",
        "    \"\"\"\n",
        "    This function just defines each abbreviation used in the previous function (e.g. LR = Logistic Regression)\n",
        "    \"\"\"\n",
        "    print('')\n",
        "    print('LR = LogisticRegression')\n",
        "    print('RF = RandomForestClassifier')\n",
        "    print('KNN = KNeighborsClassifier')\n",
        "    print('SVM = Support Vector Machine SVC')\n",
        "    print('LSVM = LinearSVC')\n",
        "    print('GNB = GaussianNB')\n",
        "    print('DTC = DecisionTreeClassifier')\n",
        "    print('GBC = GradientBoostingClassifier')\n",
        "    #print('LDA = LinearDiscriminantAnalysis')\n",
        "    print('')\n",
        "    return\n",
        "\n",
        "defineModels()\n",
        "\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "70c10cfc-0ed9-48aa-85d3-b7d1a5ba4ed9",
        "_uuid": "edf315ac60c1f1cc9d7f904ec4c7cf96e0db2907"
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "## It looks like all nine of these algorithms can do a decent job at this classification task.\n",
        "## Here we are looking at the \"Accuracy Score\".  But there is another metric called the F1\n",
        "## score that does an even better job of comparing model performance.  Let's try that now.\n",
        "## you can learn more about f1 scores at the following links:\n",
        "##     http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
        "##    http://scikit-learn.org/stable/modules/model_evaluation.html#precision-recall-f-measure-metrics\n",
        "#\n",
        "#def compareABunchOfDifferentModelsF1Score(a,b,c,d):\n",
        "#    \"\"\"\n",
        "#    compare performance of classifiers on X_train, X_test, Y_train, Y_test\n",
        "#    http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
        "#    http://scikit-learn.org/stable/modules/model_evaluation.html#precision-recall-f-measure-metrics\n",
        "#    \"\"\"   \n",
        "#\n",
        "#    print('')\n",
        "#    print('Compare Multiple Classifiers:')\n",
        "#    print('')\n",
        "#    print('F1 Score:')\n",
        "#    print('')\n",
        "#    models = []\n",
        "#    models.append(('LR', LogisticRegression()))\n",
        "#    models.append(('RF', RandomForestClassifier()))\n",
        "#    models.append(('KNN', KNeighborsClassifier()))\n",
        "#    models.append(('SVM', SVC()))\n",
        "#    models.append(('LSVM', LinearSVC()))\n",
        "#    models.append(('GNB', GaussianNB()))\n",
        "#    models.append(('DTC', DecisionTreeClassifier()))\n",
        "#    models.append(('GBC', GradientBoostingClassifier()))\n",
        "#    #models.append(('LDA', LinearDiscriminantAnalysis()))\n",
        "#        \n",
        "#    resultsF1 = []\n",
        "#    names = []\n",
        "#    for name, model in models:\n",
        "#        model.fit(a, b)\n",
        "#        kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
        "#        f1_results = model_selection.cross_val_score(model, c, d, cv=kfold, scoring='f1_macro')\n",
        "#        resultsF1.append(f1_results)\n",
        "#        names.append(name)\n",
        "#        f1Message = \"%s: %f (%f)\" % (name, f1_results.mean(), f1_results.std())\n",
        "#        print(f1Message)\n",
        "#        \n",
        "#    fig = plt.figure()\n",
        "#    fig.suptitle('Algorithm Comparison: F1 Score')\n",
        "#    ax = fig.add_subplot(111)\n",
        "#    plt.boxplot(resultsF1)\n",
        "#    ax.set_xticklabels(names)\n",
        "#    ax.set_ylabel('Cross-Validation: F1 Score')\n",
        "#    plt.show()\n",
        "#    return\n",
        "#\n",
        "#compareABunchOfDifferentModelsF1Score(X_train, Y_train, X_test, Y_test)\n",
        "#defineModels()\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "6af92975-184a-4f21-962d-a2df99d1b509",
        "_uuid": "b7666708a00b76aa96a95540ba00f71ddeefcbfc",
        "collapsed": true
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "\n",
        "# Again, it looks like all nine algorithms do a pretty decent job.\n",
        "# Let's look at three of them in more detail.\n",
        "# Logistic Regression is my favorite algorithm, so let's look at that.\n",
        "# I also like Support Vector Machines, so we will look at that as well.\n",
        "# The K-Nearest Neighbors Classifier consistently had very good F1 scores.\n",
        "# We'll look at the K-Nearest Neighbors Classifier as well.\n",
        "# And finally, let's look at the LinearDiscriminantAnalysis Classifier as well.\n",
        "# The way that we are going to further compare these four algorithms\n",
        "# is by looking at the effect of the sample size on the accuracy score\n",
        "# for both the training dataset and the cross-validation dataset.\n",
        "# For more information about learning curves, read the following documentation: \n",
        "# http://scikit-learn.org/stable/modules/learning_curve.html\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
        "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "    \"\"\"\n",
        "    Plots a learning curve. http://scikit-learn.org/stable/modules/learning_curve.html\n",
        "    \"\"\"\n",
        "    plt.figure()\n",
        "    plt.title(title)\n",
        "    if ylim is not None:\n",
        "        plt.ylim(*ylim)\n",
        "    plt.xlabel(\"Training examples\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    plt.grid()\n",
        "\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                     color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
        "             label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
        "             label=\"Cross-validation score\")\n",
        "\n",
        "    plt.legend(loc=\"best\")\n",
        "    return plt\n",
        "\n",
        "\n",
        "plot_learning_curve(LogisticRegression(), 'Learning Curve For Logistic Regression Classifier', X_train, Y_train, (0.85,1), 10)\n",
        "plot_learning_curve(SVC(), 'Learning Curve For SVM Classifier', X_train, Y_train, (0.85,1), 10)\n",
        "#plot_learning_curve(LinearDiscriminantAnalysis(), 'Learning Curve For LDA Classifier', X_train, Y_train, (0.85,1), 10)\n",
        "plot_learning_curve(KNeighborsClassifier(), 'Learning Curve For K-Nearest Neighbors Classifier', X_train, Y_train, (0.85,1), 10)\n",
        "\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "ca136a42-9648-467d-90e2-27fce92cdbe2",
        "_uuid": "48340eb15e1b5046242ff913241f148478372a09"
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "\n",
        "# Great!  These learning curves were really informative.  It looks like maybe the \n",
        "# Logistic Regression and LDA are both overfitting the data.  And the K-Nearest Neighbor Classifier\n",
        "# maybe needs an even larger sample size before the training curve and cross-validation\n",
        "# curve are ready to converge.  It looks like maybe the Support Vector Machine\n",
        "# algorithm is the best classifier to use for this application.  The learning curve\n",
        "# you see here for the Support Vector Machine suggests that we do not suffer too much\n",
        "# from either overfitting or bias.\n",
        "\n",
        "\n",
        "# So now let's run the Support Vector Machine Classifier\n",
        "\n",
        "\n",
        "# Optimize Parameters for SVM\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer, accuracy_score\n",
        "\n",
        "def selectParametersForSVM(a, b, c, d):\n",
        "    \"\"\" Select Parameters for LR using SKlearn GridSearchCV function\n",
        "    http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
        "    http://scikit-learn.org/stable/modules/grid_search.html#grid-search\"\"\"\n",
        "    model = SVC()\n",
        "    parameters = {'C': [0.01, 0.1, 0.5, 1.0, 5.0, 10, 25, 50, 100],\n",
        "                  'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}\n",
        "    accuracy_scorer = make_scorer(accuracy_score)\n",
        "    grid_obj = GridSearchCV(model, parameters, scoring=accuracy_scorer)\n",
        "    grid_obj = grid_obj.fit(a, b)\n",
        "    model = grid_obj.best_estimator_\n",
        "    model.fit(a, b)\n",
        "    print('Selected Parameters for SVM:')\n",
        "    print('')\n",
        "    print(model)\n",
        "    print('')\n",
        "#    predictions = model.predict(c)\n",
        "#    print(accuracy_score(d, predictions))\n",
        "#    print('Logistic Regression - Training set accuracy: %s' % accuracy_score(d, predictions))\n",
        "    kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
        "    accuracy = model_selection.cross_val_score(model, c, d, cv=kfold, scoring='accuracy')\n",
        "    mean = accuracy.mean() \n",
        "    stdev = accuracy.std()\n",
        "    print('Support Vector Machine - Training set accuracy: %s (%s)' % (mean, stdev))\n",
        "    print('')\n",
        "    return\n",
        "\n",
        "selectParametersForSVM(X_train, Y_train, X_test, Y_test)\n",
        "\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "508e20ca-4795-404d-a18f-295f8605b578",
        "_uuid": "a7812be3ca5867daed5c1bbdf723905fb7409e54"
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "# It looks like our model can predict with about 90% accuracty whether or not a given\n",
        "# sample is malignant.  That is pretty good!\n",
        "\n",
        "\n",
        "# Next, I will try using neural networks in an attempt to increase our accuracy.\n",
        "# Before I do that, however, I am going to make the following transformations to the data:\n",
        "# (1) Create Dummy Variables; (2) Perform Feature Selection; (3) Perform PCA trransformation\n",
        "\n",
        "\n",
        "# Replace categorical with numerical\n",
        "# implements the pd.get_dummies function to convert categorical columns to multiple binary columns\n",
        "# Learn more about get_dummies and the advantages of binary data representation at the following link:\n",
        "# https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html\n",
        "trainingDataDummies = pd.get_dummies(trainingData, columns=['texture_mean', 'area_mean', 'smoothness_mean', 'concave_points_mean', 'symmetry_mean'])\n",
        "\n",
        "# Eventually we will use neural networks.  For these algorithms, it is best to have data that is scaled.\n",
        "\n",
        "\n",
        "# Describe the data\n",
        "describeDataAgain(trainingDataDummies)\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "407fa345-d6f8-4ced-9eeb-ed384c4aa5cc",
        "_uuid": "bcc7c79b988827413e3e8019783847e168a114d1"
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "# Now we split the combined data back into training and testing data since we have finished with the feature engineering\n",
        "# Split up the training data, setting aside 20%\n",
        "# of the training data for cross-validation testing,\n",
        "#X = trainingData.iloc[0:5000,1:] \n",
        "#y = trainingData.iloc[0:5000,:1] \n",
        "xValues = trainingDataDummies.drop(['diagnosis'], axis=1)\n",
        "yValues = trainingDataDummies['diagnosis']\n",
        "#yValues = y\n",
        "# Here comes the important part\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(xValues, yValues, test_size=0.2)\n",
        "# The train_test_split function is important for cross-validation\n",
        "# Learn more about this important concept at the following links:\n",
        "#http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "#http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation\n",
        "\n",
        "# Train and cross-validate multiple classification algorithms and compare the result\n",
        "# Compare Classification Algorithms\n",
        "compareABunchOfDifferentModelsAccuracy(X_train, Y_train, X_test, Y_test)\n",
        "defineModels()\n",
        "\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "eea72651-5869-4699-84aa-7ff9e5ff7b14",
        "_uuid": "394fe1270e55a4372b9bceb2f49922329296073a"
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "\n",
        "# Now let's plot a bunch of learning curves to see if we can find a method that does not overfit the data\n",
        "# http://scikit-learn.org/stable/modules/learning_curve.html\n",
        "def plotLotsOfLearningCurves(a,b):\n",
        "    \"\"\"Now let's plot a bunch of learning curves\n",
        "    # http://scikit-learn.org/stable/modules/learning_curve.html\n",
        "    \"\"\"\n",
        "    models = []\n",
        "    models.append(('LR', LogisticRegression()))\n",
        "    models.append(('RF', RandomForestClassifier()))\n",
        "    models.append(('KNN', KNeighborsClassifier()))\n",
        "    models.append(('SVM', SVC()))\n",
        "    models.append(('LSVM', LinearSVC()))\n",
        "    #models.append(('GNB', GaussianNB()))\n",
        "    #models.append(('DTC', DecisionTreeClassifier()))\n",
        "    models.append(('GBC', GradientBoostingClassifier()))\n",
        "    #models.append(('LDA', LinearDiscriminantAnalysis()))\n",
        "    \n",
        "    for name, model in models:\n",
        "        plot_learning_curve(model, 'Learning Curve For %s Classifier'% (name), a,b, (0.8,1), 10)\n",
        "plotLotsOfLearningCurves(X_train, Y_train)\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "ef72b0ed-1021-4ebd-b4f9-02fd3047c2b2",
        "_uuid": "cf51682234ab529e52960b7019b34ce8eed09e33"
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "# Next I will do some feature selection\n",
        "\n",
        "# How many features should I eliminate?\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "def determineOptimalFeatureNumber(a,b):\n",
        "    \"\"\"\n",
        "    #http://scikit-learn.org/stable/auto_examples/feature_selection/plot_rfe_with_cross_validation.html\n",
        "    \"\"\"\n",
        "    models = []\n",
        "    models.append(('LR', LogisticRegression()))\n",
        "    models.append(('RF', RandomForestClassifier()))\n",
        "    #models.append(('KNN', KNeighborsClassifier()))\n",
        "    #models.append(('SVM', SVC()))\n",
        "    models.append(('LSVM', LinearSVC()))\n",
        "    #models.append(('GNB', GaussianNB()))\n",
        "    models.append(('DTC', DecisionTreeClassifier()))\n",
        "    models.append(('GBC', GradientBoostingClassifier()))\n",
        "    #models.append(('LDA', LinearDiscriminantAnalysis()))\n",
        "    \n",
        "    for name, model in models:\n",
        "        # Create the RFE object and compute a cross-validated score.\n",
        "        currentModel = model\n",
        "        # The \"accuracy\" scoring is proportional to the number of correct\n",
        "        # classifications\n",
        "        rfecv = RFECV(estimator=currentModel, step=1, cv=StratifiedKFold(2), scoring='accuracy')\n",
        "        rfecv.fit(a,b)\n",
        "        print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
        "        # Plot number of features VS. cross-validation scores\n",
        "        plt.figure()\n",
        "        plt.xlabel(\"Number of features selected for %s\" % (name))\n",
        "        plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
        "        plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
        "        plt.show()\n",
        "\n",
        "determineOptimalFeatureNumber(X_train, Y_train)\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "d60895a7-b43c-4124-87c3-1ed3d4c54fe2",
        "_uuid": "af83a4648204fbe148d775b7144c2fdb99c10ad3"
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "# Now we will eliminate all but the most helpful features\n",
        "# We will do this by fitting a LinearSVC and then identifying the best coefficients\n",
        "#from sklearn.model_selection import GridSearchCV\n",
        "#from sklearn.metrics import make_scorer, accuracy_score\n",
        "  \n",
        "#Run LinearSVC\n",
        "def runLinearSVC(a,b,c,d):\n",
        "    \"\"\"Run LinearSVC w/ Kfold CV\"\"\"\n",
        "    model = LinearSVC()\n",
        "    model.fit(a,b)\n",
        "    kfold = model_selection.KFold(n_splits=10)\n",
        "    accuracy = model_selection.cross_val_score(model, c,d, cv=kfold, scoring='accuracy')\n",
        "    mean = accuracy.mean() \n",
        "    stdev = accuracy.std()\n",
        "    print('LinearSVC - Training set accuracy: %s (%s)' % (mean, stdev))\n",
        "    print('')\n",
        "runLinearSVC(X_train, Y_train, X_test, Y_test)\n",
        "\n",
        "\n",
        "# Identify best feature coefficients (coef_) and/or feature importance (feature_importances_)\n",
        "model = LinearSVC()\n",
        "model.fit(X_train,Y_train) # Needed to initialize coef_\n",
        "columns = X_train.columns\n",
        "coefficients = model.coef_.reshape(X_train.columns.shape[0], 1)\n",
        "absCoefficients = abs(coefficients)\n",
        "fullList = pd.concat((pd.DataFrame(columns, columns = ['Variable']), pd.DataFrame(absCoefficients, columns = ['absCoefficient'])), axis = 1).sort_values(by='absCoefficient', ascending = False)\n",
        "print('LinearSVC - Feature Importance:')\n",
        "print('')\n",
        "print(fullList)\n",
        "print('')\n",
        "# Remove all but the most helpful features\n",
        "### Note that if I was worried about overfitting the training data I would eliminate a lot of features\n",
        "### Right now I am not too worried about overfitting and would rather retain as much information as possible since it is all very relevant.\n",
        "### As such I will limit us to 50 features, which ends up not eliminating any features at all.\n",
        "topTwenty = fullList[:50]\n",
        "featureList = topTwenty.values\n",
        "featureList = pd.DataFrame(featureList)\n",
        "featuresOnly = featureList[0]\n",
        "featuresOnly = list(featuresOnly)\n",
        "featuresOnly += ['diagnosis']\n",
        "trainingDataDummies = trainingDataDummies[featuresOnly]\n",
        "#g = sns.heatmap(trainingData[featuresOnly].corr(),cmap=\"BrBG\",annot=False)\n",
        "\n",
        "# Let's see if we improved our accuracy scores\n",
        "\n",
        "# Split up the training data, setting aside 20%\n",
        "# of the training data for cross-validation testing,\n",
        "#X = trainingData.iloc[0:5000,1:] \n",
        "#y = trainingData.iloc[0:5000,:1] \n",
        "xValues = trainingDataDummies.drop(['diagnosis'], axis=1)\n",
        "yValues = trainingDataDummies['diagnosis']\n",
        "#yValues = y\n",
        "# Here comes the important part\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(xValues, yValues, test_size=0.2)\n",
        "# The train_test_split function is important for cross-validation\n",
        "# Learn more about this important concept at the following links:\n",
        "#http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "#http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation\n",
        "\n",
        "print('')\n",
        "print('Dataset reduced to the following columns:')\n",
        "print('')\n",
        "print(X_train.columns)\n",
        "\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "79a05e3e-b8ca-4831-995b-330c77bebbe6",
        "_uuid": "8af63e0224187a4bddd85e2dbf8a2e5f932c0c9d"
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "## See if the score of the Linear SVC improved after narrowing down the number of features\n",
        "# Run LSVC\n",
        "print('')\n",
        "print('After feature selection:')\n",
        "print('')\n",
        "runLinearSVC(X_train, Y_train, X_test, Y_test)\n",
        "\n",
        "\n",
        "# And now let's see how the other classification algorithms like the reduction in features\n",
        "print('After Feature Selection')\n",
        "print('')\n",
        "compareABunchOfDifferentModelsAccuracy(X_train, Y_train, X_test, Y_test)\n",
        "defineModels()\n",
        "\n",
        "#"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "f774866a-4e41-4ce5-882f-d09d80ce0c42",
        "_uuid": "1e7c7892ae0d515d35269e756279f4d4be017b73"
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "###\n",
        "###\n",
        "###\n",
        "\n",
        "## We want to use some linear classifiers, so we need to make sure that none of our features are too hgihly correlated\n",
        "## First let's look at a heatmap of correlations between each feature\n",
        "#\n",
        "#g = sns.heatmap(X_train.corr(),cmap=\"BrBG\",annot=False)\n",
        "#\n",
        "#\n",
        "## Some of these features are highly correlated \n",
        "## This can cause problems for some algorithms such as linear classifiers\n",
        "## As such, we will now transform our features to make them no longer be correlated\n",
        "## this is done by applying a transformation and dimensionality reduction to the data\n",
        "## this process is called principal component analysis (PCA)\n",
        "## Fore more info, see the following documentaion:\n",
        "## http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
        "## http://scikit-learn.org/stable/modules/decomposition.html#pca\n",
        "##\n",
        "#\n",
        "## Now let's do a PCA to help with multicollinearity between the remaining features\n",
        "#from sklearn.decomposition import PCA\n",
        "## Minimum percentage of variance we want to be described by the resulting transformed components\n",
        "#variance_pct = .99\n",
        "## Create PCA object\n",
        "#pca = PCA(n_components=variance_pct)\n",
        "## Transform the initial features\n",
        "#X_transformed = pca.fit_transform(xValues,yValues)\n",
        "##X_transformedTest = pca.fit_transform(xValuesTest,y)\n",
        "##testingData = testingData[X_transformedTest]\n",
        "## Create a data frame from the PCA'd data\n",
        "#pcaDataFrame = pd.DataFrame(X_transformed) \n",
        "##print(pcaDataFrame.shape[1], \" components describe \", str(variance_pct)[1:], \"% of the variance\")\n",
        "## Redefine X_train, X_test, Y_train, Y_test\n",
        "#xValues = pcaDataFrame\n",
        "#yValues = yValues\n",
        "##yValues = y\n",
        "## Here comes the important part\n",
        "#X_train, X_test, Y_train, Y_test = train_test_split(xValues, yValues, test_size=0.2)\n",
        "#\n",
        "## Now we have new features (we transformed them) with new names\n",
        "## There are fewer numbers of features now (dimensionality reduction)\n",
        "## The features are no longer correlated, as illustrated below:\n",
        "#\n",
        "#g = sns.heatmap(X_train.corr(),cmap=\"BrBG\",annot=False)\n",
        "#\n",
        "## Alternatively we could have done this:\n",
        "### First We will eliminate anything with a correlation score greater than .5\n",
        "##def correlation(dataset, threshold):\n",
        "##    col_corr = set() # Set of all the names of deleted columns\n",
        "##    corr_matrix = dataset.corr()\n",
        "##    for i in range(len(corr_matrix.columns)):\n",
        "##        for j in range(i):\n",
        "##            if corr_matrix.iloc[i, j] >= threshold:\n",
        "##                colname = corr_matrix.columns[i] # getting the name of column\n",
        "##                col_corr.add(colname)\n",
        "##                if colname in dataset.columns:\n",
        "##                    del dataset[colname] # deleting the column from the dataset\n",
        "##    print('')\n",
        "##    print('Dataset reduced to the following columns:')\n",
        "##    print('')\n",
        "##    print(dataset.columns)\n",
        "##\n",
        "##correlation(X_train, 0.5)\n",
        "##correlation(X_test, 0.5)\n",
        "#\n",
        "## Our newly transformed featuers are no longer correlated.\n",
        "#\n",
        "#\n",
        "## See if the score of the LinearSVC improved after the Feature Selection + PCA\n",
        "#\n",
        "## Run LSVC\n",
        "#print('')\n",
        "#print('After feature selection + PCA:')\n",
        "#print('')\n",
        "#runLinearSVC(X_train, Y_train, X_test, Y_test)\n",
        "#\n",
        "## Run classifiers after PCA\n",
        "#print('After Feature Selection + PCA')\n",
        "#print('')\n",
        "#compareABunchOfDifferentModelsAccuracy(X_train, Y_train, X_test, Y_test)\n",
        "#defineModels()\n",
        "#\n",
        "## Plot learning curve\n",
        "#\n",
        "#plot_learning_curve(LinearSVC(), 'Learning Curve For %s Classifier'% ('LinearSVC'), X_train, Y_train, (0.75,0.95), 10)\n",
        "#plot_learning_curve(LogisticRegression(), 'Learning Curve For %s Classifier'% ('LogisticRegression'), X_train, Y_train, (0.75,0.95), 10)\n",
        "#\n",
        "## Those learning curves look great.\n",
        "\n",
        "###\n",
        "###\n",
        "###\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "6566e4d9-313c-4fdd-8cd2-2630d6b447d0",
        "_uuid": "55273d369070920d73ccd63aea899059ab2c77ae",
        "collapsed": true
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "# Optimize Parameters for LSVC\n",
        "\n",
        "# To select parameters, we use the functino grid_searchCV\n",
        "# To learn more about this function, see the following documentation:\n",
        "# http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
        "#http://scikit-learn.org/stable/modules/grid_search.html#grid-search\n",
        "\n",
        "# Optimize Parameters for LSVM\n",
        "\n",
        "def selectParametersForLSVM(a, b, c, d):\n",
        "    \"\"\"http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
        "    http://scikit-learn.org/stable/modules/grid_search.html#grid-search\"\"\"\n",
        "    model = LinearSVC()\n",
        "    parameters = {'C': [0.00001, 0.001, .01, 0.1, 0.5, 1.0, 5.0, 10, 25, 50, 100, 1000]}\n",
        "    accuracy_scorer = make_scorer(accuracy_score)\n",
        "    grid_obj = GridSearchCV(model, parameters, scoring=accuracy_scorer)\n",
        "    grid_obj = grid_obj.fit(a, b)\n",
        "    model = grid_obj.best_estimator_\n",
        "    model.fit(a, b)\n",
        "    print('Selected Parameters for LSVM:')\n",
        "    print('')\n",
        "    print(model)\n",
        "    print('')\n",
        "#    predictions = model.predict(c)\n",
        "#    print(accuracy_score(d, predictions))\n",
        "#    print('Logistic Regression - Training set accuracy: %s' % accuracy_score(d, predictions))\n",
        "    kfold = model_selection.KFold(n_splits=10)\n",
        "    accuracy = model_selection.cross_val_score(model, c, d, cv=kfold, scoring='accuracy')\n",
        "    mean = accuracy.mean() \n",
        "    stdev = accuracy.std()\n",
        "    print('Linear Support Vector Machine - Training set accuracy: %s (%s)' % (mean, stdev))\n",
        "    print('')\n",
        "    return\n",
        "selectParametersForLSVM(X_train, Y_train, X_test, Y_test)\n",
        "\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "84b638a4-739c-4f19-a84d-13d91f9008f8",
        "_uuid": "25d475abe0ea42c84edbfe33643b2c2eb4955985"
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "# Let's also try running a few Neural Networks\n",
        "\n",
        "# First we will use the Multi-layer Perceptron NN model from Sklearn\n",
        "from sklearn.neural_network import MLPClassifier as MLPC\n",
        "def runMLPC(a,b,c,d):\n",
        "    classifier = MLPC(activation='relu', max_iter=1000)\n",
        "    classifier.fit(a, b)\n",
        "    kfold = model_selection.KFold(n_splits=10)\n",
        "    accuracy = model_selection.cross_val_score(classifier, c, d, cv=kfold, scoring='accuracy')\n",
        "    mean = accuracy.mean() \n",
        "    stdev = accuracy.std()\n",
        "    print('SKlearn Multi-layer Perceptron NN - Training set accuracy: %s (%s)' % (mean, stdev))\n",
        "    print('')\n",
        "runMLPC(X_train, Y_train,  X_test, Y_test)\n",
        "\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "a09dd8af-32f7-462a-a136-3e3049eb637c",
        "_uuid": "643d9a0aed6a5256d97f0e31f7179ee35ad8398a"
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "# Now let's see if we can improve the score with parameter optimization\n",
        "# Optimize Parameters for MLP-NN\n",
        "\n",
        "def selectParametersForMLPC(a, b, c, d):\n",
        "    \"\"\"http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
        "    http://scikit-learn.org/stable/modules/grid_search.html#grid-search\"\"\"\n",
        "    model = MLPC()\n",
        "    parameters = {'verbose': [False],\n",
        "                  'activation': ['logistic', 'relu'],\n",
        "                  'max_iter': [1000, 2000], 'learning_rate': ['constant', 'adaptive']}\n",
        "    accuracy_scorer = make_scorer(accuracy_score)\n",
        "    grid_obj = GridSearchCV(model, parameters, scoring=accuracy_scorer)\n",
        "    grid_obj = grid_obj.fit(a, b)\n",
        "    model = grid_obj.best_estimator_\n",
        "    model.fit(a, b)\n",
        "    print('Selected Parameters for Multi-Layer Perceptron NN:')\n",
        "    print('')\n",
        "    print(model)\n",
        "    print('')\n",
        "#    predictions = model.predict(c)\n",
        "#    print(accuracy_score(d, predictions))\n",
        "#    print('Logistic Regression - Training set accuracy: %s' % accuracy_score(d, predictions))\n",
        "    kfold = model_selection.KFold(n_splits=10)\n",
        "    accuracy = model_selection.cross_val_score(model, c, d, cv=kfold, scoring='accuracy')\n",
        "    mean = accuracy.mean() \n",
        "    stdev = accuracy.std()\n",
        "    print('SKlearn Multi-Layer Perceptron - Training set accuracy: %s (%s)' % (mean, stdev))\n",
        "    print('')\n",
        "    return\n",
        "\n",
        "selectParametersForMLPC(X_train, Y_train,  X_test, Y_test)\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "06cd43b7-19ca-4be2-8380-1b8b806ae9e9",
        "_uuid": "618ba5c38a98031e5eb6c449db3976a9f1ad0b1d"
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "# Now let's try some other neural networks\n",
        "from __future__ import print_function\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# We will build some custom neural networks using keras\n",
        "# https://keras.io/models/sequential/\n",
        "\n",
        "def runTwoKerasClassifiers(a,b,c,d):\n",
        "    \"\"\" Build and run Two different NNs using Keras\"\"\"\n",
        "    global kerasModelOne, kerasModelTwo # eventually I should get rid of these global variables and use classes instead.  in this case i need these variables for the submission function.\n",
        "    # Let's start out with a simple network consisting of only two fully connected layers.\n",
        "    Adagrad(lr=0.00001, epsilon=1e-08, decay=0.0)\n",
        "    model = Sequential()\n",
        "    model.add(Dense(input_dim=np.array(a).shape[1], units=128, kernel_initializer='normal', bias_initializer='zeros'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(units=1))\n",
        "    model.add(Activation('sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='Adagrad', metrics=['accuracy'])\n",
        "    model.fit(np.array(a), np.array(b), epochs=10, verbose=2, validation_split=0.2)\n",
        "    score = model.evaluate(np.array(c),np.array(d), verbose=0)\n",
        "    print('')\n",
        "    print('Loss, Accuracy:')\n",
        "    print(score)\n",
        "    kerasModelOne = model  \n",
        "    # Now let's make a new network, a deep network, that has 15 additional fully connected layers and also 15 dropout functions\n",
        "    #RMSprop(lr=0.00001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
        "    Adagrad(lr=0.00001, epsilon=1e-08, decay=0.0)\n",
        "    #Adadelta(lr=0.00001, rho=0.95, epsilon=1e-08, decay=0.0)\n",
        "    model = Sequential()\n",
        "    model.add(Dense(input_dim=np.array(a).shape[1], units=128,\n",
        "                     kernel_initializer='normal', bias_initializer='zeros'))\n",
        "    model.add(Activation('relu'))\n",
        "    for i in range(0, 15):\n",
        "        model.add(Dense(units=128, kernel_initializer='normal',\n",
        "                         bias_initializer='zeros'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(Dropout(.40))\n",
        "    model.add(Dense(units=1))\n",
        "    model.add(Activation('sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='Adagrad', metrics=['accuracy'])\n",
        "    print('Running Deep Neural Network: Expect Delays')\n",
        "    model.fit(np.array(a), np.array(b), epochs=10, verbose=2, validation_split=0.2)\n",
        "    score = model.evaluate(np.array(c),np.array(d), verbose=0)\n",
        "    print('')\n",
        "    print('Loss, Accuracy:')\n",
        "    print(score)\n",
        "    kerasModelTwo = model\n",
        "    return kerasModelOne, kerasModelTwo\n",
        "runTwoKerasClassifiers(X_train,Y_train,X_test,Y_test)\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "f8e5d9dd-17eb-4061-b934-68c90ce86278",
        "_uuid": "6af2d012c56a5a97bc483016faca16b937813422"
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "# To try to get an even higher score, I will now combine the MLPC and LSVC/SVM methods by using a new method called ensemble voting.\n",
        "# It only works with Sklearn classifiers so that is why I did not include Keras.\n",
        "# This new method should help to avoid overfitting by taking into consideration both MLPC and SVMs predictions.\n",
        "# To learn more about the VotingClassifier function, see the following documentation:\n",
        "# http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n",
        "# http://scikit-learn.org/stable/modules/ensemble.html#voting-classifier\n",
        "\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "def runVotingClassifier(a,b,c,d):\n",
        "    \"\"\"http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n",
        "    http://scikit-learn.org/stable/modules/ensemble.html#voting-classifier\"\"\"\n",
        "    global votingC, mean, stdev # eventually I should get rid of these global variables and use classes instead.  in this case i need these variables for the submission function.\n",
        "    votingC = VotingClassifier(estimators=[('LSVM', LinearSVC(C=0.0001, class_weight=None, dual=True, fit_intercept=True,\n",
        "         intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
        "         multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
        "         verbose=0)), ('MLPC', MLPC(activation='logistic', alpha=0.0001, batch_size='auto',\n",
        "           beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
        "           hidden_layer_sizes=(100,), learning_rate='constant',\n",
        "           learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
        "           nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
        "           shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
        "           verbose=False, warm_start=False))], voting='hard')  \n",
        "    votingC = votingC.fit(a,b)   \n",
        "    kfold = model_selection.KFold(n_splits=10)\n",
        "    accuracy = model_selection.cross_val_score(votingC, c,d, cv=kfold, scoring='accuracy')\n",
        "    meanC = accuracy.mean() \n",
        "    stdevC = accuracy.std()\n",
        "    print('Ensemble Voting Method - Training set accuracy: %s (%s)' % (meanC, stdevC))\n",
        "    print('')\n",
        "    return votingC, meanC, stdevC\n",
        "runVotingClassifier(X_train,Y_train,X_test,Y_test)\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "83f96935-a8a3-4bd0-8ca2-b984e338e008",
        "_uuid": "b6f9d01bed298c71a03927a160a32ac57fa344bd"
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "# Now let's evaluate our predictions by making a confusion matrix\n",
        "# To learn more about this confusion matrix, see the following documentation:\n",
        "# http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
        "\n",
        "# It looks like the Multi-Layer Perceptron NN was the best classifier.\n",
        "\n",
        "# First Make a Prediction\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "model = MLPC()\n",
        "model.fit(X_train, Y_train)\n",
        "prediction = model.predict(X_test)\n",
        "\n",
        "# Now plot the confusion matrix\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "# Compute confusion matrix\n",
        "cnf_matrix = confusion_matrix(Y_test, prediction)\n",
        "np.set_printoptions(precision=2)\n",
        "# Plot non-normalized confusion matrix\n",
        "class_names = [\"Diagnosis 0\", \"Diagnosis 1\"]\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "# Plot normalized confusion matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "runMLPC(X_train, Y_train,  X_test, Y_test)\n",
        "\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "3778057f-e404-4365-9de4-fe9633b9b935",
        "_uuid": "19df555e5985124e18eeb6452ab1e239e0bfa7f8"
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "\n",
        "# 94.6% accuracy! Great!  But let's see if we can do even better.\n",
        "# In the beginning of this approach I deleted most of columns of data to simplify the analysis.\n",
        "# Now I will repeat the analysis using the full dataset.\n",
        "\n",
        "\n",
        "\n",
        "#################\n",
        "#################\n",
        "# Part Two: 95% Accuracy with the Full Dataset\n",
        "#################\n",
        "#################\n",
        "\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "4a65b572-861f-4cf8-b5ff-7a3407f33dda",
        "_uuid": "a66606a4c4387c128a7e0b01a74fb776cfb9d747",
        "collapsed": true
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "\n",
        "# Load the data\n",
        "trainingData = pd.read_csv('../input/data.csv')\n",
        "diagnosisToBinary(trainingData)    \n",
        "xValues = trainingData.drop(['diagnosis', 'Unnamed: 32', 'id'], axis=1)\n",
        "yValues = trainingData['diagnosis']\n",
        "describeDataAgain(xValues)\n",
        "\n",
        "# Previously we scaled our data between zero and five.\n",
        "# We did this by making bins based off of the distribution profiles.\n",
        "# This was helpful because it allowed us to extract information\n",
        "# from the distribution profiles while making the bins.\n",
        "# Now we have a lot more features, however, and it is no longer\n",
        "# Practical to go plot each distribution profile and extrat\n",
        "# five meaningful bins. Instead, we will scale all of the data \n",
        "# between zero and one by using SKlearn's \"scale function\"\n",
        "\n",
        "\n",
        "# Scale the data\n",
        "# Here I scale the xValues by subtracting by the mean and dividing by the stdev\n",
        "# This gives us values that are centered around zero and this\n",
        "# makes it easier for us to use certain classifiers.\n",
        "from sklearn import preprocessing\n",
        "xValuesScaled = preprocessing.scale(xValues)\n",
        "xValuesScaled = pd.DataFrame(xValuesScaled, columns = xValues.columns)\n",
        "describeDataAgain(xValuesScaled)\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "93782c52-6fc1-41c3-9446-28e9a5f0c442",
        "_uuid": "0ec74b80e77999bc4910b21c9937965f73799d20"
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "# Split data for cross-validation\n",
        "# We will need to split up our training data, setting aside 20%\n",
        "# of the training data for cross-validation testing, such that we can avoid\n",
        "# potentially overfitting the data.\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(xValuesScaled, yValues, test_size=0.2, random_state=23)\n",
        "# The train_test_split function is important for cross-validation\n",
        "# Learn more about this important concept at the following links:\n",
        "#http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "#http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation\n",
        "\n",
        "compareABunchOfDifferentModelsAccuracy(X_train, Y_train, X_test, Y_test)"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "81498c37-53b1-41fc-a838-04ce6584c64c",
        "_uuid": "dbdd25650ed9090a6aba4af860f3e093fe56a9a1"
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "# We want to use some linear classifiers, so we need to make sure that none of our features are too hgihly correlated\n",
        "# First let's look at a heatmap of correlations between each feature\n",
        "\n",
        "g = sns.heatmap(X_train.corr(),cmap=\"BrBG\",annot=False)\n",
        "\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "8db81371-bb0e-4b6c-a460-ec97eeb72784",
        "_uuid": "0d862728384d4dea1613d06c6b2d09d5f3da93e2"
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "# Some of these features are highly correlated \n",
        "# This can cause problems for some algorithms such as linear classifiers\n",
        "# As such, we will now transform our features to make them no longer be correlated\n",
        "# this is done by applying a transformation and dimensionality reduction to the data\n",
        "# this process is called principal component analysis (PCA)\n",
        "# Fore more info, see the following documentaion:\n",
        "# http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
        "# http://scikit-learn.org/stable/modules/decomposition.html#pca\n",
        "#\n",
        "\n",
        "# Now let's do a PCA to help with multicollinearity between the remaining features\n",
        "from sklearn.decomposition import PCA\n",
        "# Minimum percentage of variance we want to be described by the resulting transformed components\n",
        "variance_pct = .99\n",
        "# Create PCA object\n",
        "pca = PCA(n_components=variance_pct)\n",
        "# Transform the initial features\n",
        "X_transformed = pca.fit_transform(xValuesScaled,yValues)\n",
        "#X_transformedTest = pca.fit_transform(xValuesTest,y)\n",
        "#testingData = testingData[X_transformedTest]\n",
        "# Create a data frame from the PCA'd data\n",
        "pcaDataFrame = pd.DataFrame(X_transformed) \n",
        "#print(pcaDataFrame.shape[1], \" components describe \", str(variance_pct)[1:], \"% of the variance\")\n",
        "# Redefine X_train, X_test, Y_train, Y_test\n",
        "xValues = pcaDataFrame\n",
        "yValues = yValues\n",
        "#yValues = y\n",
        "# Here comes the important part\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(xValues, yValues, test_size=0.2)\n",
        "\n",
        "# Now we have new features (we transformed them) with new names\n",
        "# There are fewer numbers of features now (dimensionality reduction)\n",
        "# The features are no longer correlated, as illustrated below:\n",
        "\n",
        "g = sns.heatmap(X_train.corr(),cmap=\"BrBG\",annot=False)\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "87084865-6545-4ac2-a38a-e255ebcd512e",
        "_uuid": "b831485c6966b2972e5ee0434cf1f922f3336b3e"
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "# See if the score of the LinearSVC improved after the Feature Selection + PCA\n",
        "\n",
        "# Run LSVC\n",
        "print('')\n",
        "print('After feature selection + PCA:')\n",
        "print('')\n",
        "runLinearSVC(X_train, Y_train, X_test, Y_test)\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "8b41952c-9373-4b62-bf0c-f3a3e36d9830",
        "_uuid": "d07160686de5462fb26fd35eac164be0f4643861"
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "# Run classifiers after PCA\n",
        "print('After Feature Selection + PCA')\n",
        "print('')\n",
        "compareABunchOfDifferentModelsAccuracy(X_train, Y_train, X_test, Y_test)\n",
        "defineModels()\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "112cd4cd-65eb-40f3-b078-960805e06308",
        "_uuid": "d5f5f17b4f8db4e0313ff1696e508a3d5f44652e"
      }
    },
    {
      "execution_count": null,
      "source": [
        "runMLPC(X_train, Y_train,  X_test, Y_test)\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "3cc504c2-ebb1-477f-8937-28bfb00ba601",
        "_uuid": "ec997d4d9c66ed0ade0f33a96330fd1a8193607e"
      }
    },
    {
      "execution_count": null,
      "source": [
        "runTwoKerasClassifiers(X_train,Y_train,X_test,Y_test)\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "ade5de20-6e64-4265-ade9-f85af8d7970c",
        "_uuid": "18e6c24b49d1523d0156748ee59324d4eb0c6bad"
      }
    },
    {
      "execution_count": null,
      "source": [
        "\n",
        "# It looks like the Logistic Regression is the best classifier.\n",
        "\n",
        "# First Make a Prediction\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, Y_train)\n",
        "prediction = model.predict(X_test)\n",
        "\n",
        "# Now plot the confusion matrix\n",
        "# Compute confusion matrix\n",
        "cnf_matrix = confusion_matrix(Y_test, prediction)\n",
        "np.set_printoptions(precision=2)\n",
        "# Plot non-normalized confusion matrix\n",
        "class_names = [\"Diagnosis 0\", \"Diagnosis 1\"]\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "# Plot normalized confusion matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Run LR\n",
        "def runLR(a,b,c,d):\n",
        "    \"\"\"Run LR w/ Kfold CV\"\"\"\n",
        "    model = LogisticRegression()\n",
        "    model.fit(a,b)\n",
        "    kfold = model_selection.KFold(n_splits=10)\n",
        "    accuracy = model_selection.cross_val_score(model, c,d, cv=kfold, scoring='accuracy')\n",
        "    mean = accuracy.mean() \n",
        "    stdev = accuracy.std()\n",
        "    print('Logistic Regression - Training set accuracy: %s (%s)' % (mean, stdev))\n",
        "    print('')\n",
        "runLR(X_train, Y_train, X_test, Y_test)\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "bd1cd0ba-1ffc-4da2-8652-d840c1868317",
        "_uuid": "587cd6da58cea979ae328d725b181f3444bc01a3"
      }
    },
    {
      "execution_count": null,
      "source": [
        "# 95% accuracy!  Great!  I think it is safe to say that we can accurately predict\n",
        "# the diagnosis for most any given patient.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# To produce a new CSV document containing your predictions based off \n",
        "# of nuclear shape measurements contained in test.csv, see the following code:\n",
        "\n",
        "# Submission with Ensemble Voting Classification Method\n",
        "\n",
        "## Load testing Data (to extract PassengerID Only)\n",
        "#testingData2 = pd.read_csv('test.csv')\n",
        "## Define Model, Predict, Submitmodel = votingC\n",
        "#model = votingC\n",
        "#model.fit(X_train, Y_train)\n",
        "#prediction = model.predict(testingData)\n",
        "#prediction = prediction.astype(int)\n",
        "#submission = pd.DataFrame({\n",
        "#    \"PassengerId\": testingData2[\"PassengerId\"],\n",
        "#    \"Survived\": prediction})\n",
        "#submission.to_csv('_new_submission_ensemble.csv', index=False)\n",
        "#\n",
        "## to finish the submission process, upload the file '_new_submission_.csv' to Kaggle\n",
        "#\n",
        "#\n",
        "##_Alternative Submission for Keras\n",
        "#\n",
        "## Re-Load testing Data (to extract PassengerID Only)\n",
        "#testingData2 = pd.read_csv('test.csv')\n",
        "## Define Model, Predict, Submit\n",
        "#model = kerasModelTwo\n",
        "#model.fit(np.array(X_train), np.array(Y_train), epochs=50, verbose=2, validation_split=0.2)\n",
        "#prediction = model.predict_classes(np.array(testingData))\n",
        "#submission = pd.DataFrame({\"PassengerId\": testingData2[\"PassengerId\"], \"Survived\": prediction.flatten()})\n",
        "#submission.to_csv('_new_submission_Keras.csv', index=False)\n",
        "#\n",
        "## to finish the submission process, upload the file '_new_submission_.csv' to Kaggle\n",
        "#\n",
        "## Submission with LinearSVC\n",
        "#\n",
        "## Load testing Data (to extract PassengerID Only)\n",
        "#testingData2 = pd.read_csv('test.csv')\n",
        "## Define Model, Predict, Submitmodel = votingC\n",
        "#model = LinearSVC(C=0.0001, class_weight=None, dual=True, fit_intercept=True,intercept_scaling=1, loss='squared_hinge', max_iter=1000,multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,verbose=0)\n",
        "#model.fit(X_train, Y_train)\n",
        "#prediction = model.predict(testingData)\n",
        "#prediction = prediction.astype(int)\n",
        "#submission = pd.DataFrame({\n",
        "#    \"PassengerId\": testingData2[\"PassengerId\"],\n",
        "#    \"Survived\": prediction})\n",
        "#submission.to_csv('_new_submission_LinearSVC.csv', index=False)\n",
        "#\n",
        "## to finish the submission process, upload the file '_new_submission_.csv' to Kaggle\n",
        "#"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "26552745-e499-437d-90f9-35cd20c230d8",
        "_uuid": "4b4cd211abb9342b65a909f828c750df7eabdef4",
        "collapsed": true
      }
    }
  ],
  "metadata": {
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "version": "3.6.3",
      "mimetype": "text/x-python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    }
  }
}

######
#######

