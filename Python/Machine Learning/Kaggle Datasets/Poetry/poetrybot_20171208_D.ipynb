{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pronouncing\n",
    "#!pip install markovify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_97 (LSTM)               (None, 2, 4)              112       \n",
      "_________________________________________________________________\n",
      "lstm_98 (LSTM)               (None, 2, 8)              416       \n",
      "_________________________________________________________________\n",
      "lstm_99 (LSTM)               (None, 2, 8)              544       \n",
      "_________________________________________________________________\n",
      "lstm_100 (LSTM)              (None, 2, 8)              544       \n",
      "_________________________________________________________________\n",
      "lstm_101 (LSTM)              (None, 2, 8)              544       \n",
      "_________________________________________________________________\n",
      "lstm_102 (LSTM)              (None, 2, 2)              88        \n",
      "=================================================================\n",
      "Total params: 2,248\n",
      "Trainable params: 2,248\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Alright, building the list of all the rhymes\n",
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '\"', '\"', '\"', '\"', \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", \"'\", ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', '[', ']', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'c', 'c', 'c', 'd', 'd', 'd', 'd', 'd', 'd', 'd', 'd', 'd', 'd', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'g', 'g', 'g', 'g', 'g', 'h', 'h', 'h', 'h', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'k', 'k', 'k', 'k', 'k', 'k', 'k', 'k', 'k', 'l', 'l', 'l', 'l', 'l', 'l', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 't', 't', 't', 't', 't', 't', 't', 't', 't', 't', 't', 'u', 'u', 'u', 'u', 'u', 'v', 'v', 'w', 'w', 'x', 'y', 'y', 'y', 'y', 'y', 'y', 'y', 'Ã®']\n",
      "Epoch 1/30\n",
      "1001/1001 [==============================] - 5s - loss: 0.1673     \n",
      "Epoch 2/30\n",
      "1001/1001 [==============================] - 4s - loss: 0.0726     \n",
      "Epoch 3/30\n",
      "1001/1001 [==============================] - 4s - loss: 0.0685     \n",
      "Epoch 4/30\n",
      "1001/1001 [==============================] - 4s - loss: 0.0642     \n",
      "Epoch 5/30\n",
      "1001/1001 [==============================] - 4s - loss: 0.0583     \n",
      "Epoch 6/30\n",
      "1001/1001 [==============================] - 4s - loss: 0.0554     \n",
      "Epoch 7/30\n",
      "1001/1001 [==============================] - 4s - loss: 0.0543     \n",
      "Epoch 8/30\n",
      "1001/1001 [==============================] - 4s - loss: 0.0540     \n",
      "Epoch 9/30\n",
      "1001/1001 [==============================] - 4s - loss: 0.0538     \n",
      "Epoch 10/30\n",
      "1001/1001 [==============================] - 4s - loss: 0.0535     \n",
      "Epoch 11/30\n",
      "1001/1001 [==============================] - 4s - loss: 0.0533     \n",
      "Epoch 12/30\n",
      "1001/1001 [==============================] - 4s - loss: 0.0533     \n",
      "Epoch 13/30\n",
      "1001/1001 [==============================] - 4s - loss: 0.0532     \n",
      "Epoch 14/30\n",
      "1001/1001 [==============================] - 4s - loss: 0.0532     \n",
      "Epoch 15/30\n",
      "1001/1001 [==============================] - 4s - loss: 0.0531     \n",
      "Epoch 16/30\n",
      "1001/1001 [==============================] - 4s - loss: 0.0531     \n",
      "Epoch 17/30\n",
      "1001/1001 [==============================] - 4s - loss: 0.0531     \n",
      "Epoch 18/30\n",
      "1001/1001 [==============================] - 4s - loss: 0.0531     \n",
      "Epoch 19/30\n",
      "1001/1001 [==============================] - 4s - loss: 0.0530     \n",
      "Epoch 20/30\n",
      "1001/1001 [==============================] - 4s - loss: 0.0530     \n",
      "Epoch 21/30\n",
      "1001/1001 [==============================] - 4s - loss: 0.0530     \n",
      "Epoch 22/30\n",
      "1001/1001 [==============================] - 4s - loss: 0.0530     \n",
      "Epoch 23/30\n",
      "1001/1001 [==============================] - 4s - loss: 0.0530     \n",
      "Epoch 24/30\n",
      "1001/1001 [==============================] - 4s - loss: 0.0529     \n",
      "Epoch 25/30\n",
      "1001/1001 [==============================] - 4s - loss: 0.0531     \n",
      "Epoch 26/30\n",
      "1001/1001 [==============================] - 4s - loss: 0.0530     \n",
      "Epoch 27/30\n",
      "1001/1001 [==============================] - 4s - loss: 0.0531     \n",
      "Epoch 28/30\n",
      "1001/1001 [==============================] - 4s - loss: 0.0530     \n",
      "Epoch 29/30\n",
      "1001/1001 [==============================] - 4s - loss: 0.0530     \n",
      "Epoch 30/30\n",
      "1001/1001 [==============================] - 4s - loss: 0.0529     \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_103 (LSTM)              (None, 2, 4)              112       \n",
      "_________________________________________________________________\n",
      "lstm_104 (LSTM)              (None, 2, 8)              416       \n",
      "_________________________________________________________________\n",
      "lstm_105 (LSTM)              (None, 2, 8)              544       \n",
      "_________________________________________________________________\n",
      "lstm_106 (LSTM)              (None, 2, 8)              544       \n",
      "_________________________________________________________________\n",
      "lstm_107 (LSTM)              (None, 2, 8)              544       \n",
      "_________________________________________________________________\n",
      "lstm_108 (LSTM)              (None, 2, 2)              88        \n",
      "=================================================================\n",
      "Total params: 2,248\n",
      "Trainable params: 2,248\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "loading saved network: dr_seuss.rap\n",
      "loading saved rhymes from dr_seuss.rhymes\n",
      "\n",
      "\n",
      "\n",
      "About to write rap (this could take a moment)...\n",
      "\n",
      "\n",
      "\n",
      "When your mother asked YOU?\n",
      "But that is not a good game\n",
      "Some have six feet and some are blue.\n",
      "You may like them with a PLOP!\n",
      "Freezy trees made these three trees freeze.\n",
      "I will eat them on a train\n",
      "Did not know go ask your Pop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I bet with my Ish wish dish.\n",
      "And I said How do you do?\n",
      "HILL WILL Will went up the chimney!\n",
      "Would you like them here or there.\n",
      "So he paused. And the fan and the fish.\n",
      "I have a little bit more!\n",
      "we see them come we see them come we see them go.\n",
      "With this coat and this is why:\n",
      "Should have a bird I like this?\n",
      "And I will not with a fox?\n",
      "It could be his head he had a book.\n",
      "Should have a little toy man!\n",
      "If you have to get rid of\n",
      "We saw him step in on the ball!\n",
      "Did you have to be so dumb now.\n",
      "He picked up the chimney with glee.\n",
      "I do not like them in the pot.\n",
      "Then out of bed for a mouse.\n",
      "Oh no! I do not like them\n",
      "So we sat in the park in the Hat!\n",
      "When our mother came in\n",
      "Come down! We have to know how.\n",
      "Bricks and blocks and clocks sir.\n",
      "I will not with a box.\n",
      "Said the fish in the hot hot sun.\n",
      "How The Grinch looked around.\n",
      "Her gown with the fan and the small\n",
      "Hop hop! I am in bed.\n",
      "I always pick up the cup\n",
      "And he stuffed them in the dark?\n",
      "Too wet to go Bump! Bump!\n",
      "But that is not sunny.\n",
      "We saw him pick up the cake\n",
      "Then I said to us two\n",
      "I like to fly kites\n",
      "I could not in a house.\n",
      "We sat there with Sally.\n",
      "I will eat them here or there.\n",
      "But your mother asked YOU?\n",
      "Some are old and some have more.\n",
      "and that is not right.\n",
      "Good trick that I call\n",
      "Hop hop! I am Sam\n",
      "Thing Two and Thing Two?\n",
      "First Ill make a wish\n",
      "They are so good you see!\n",
      "But that is funny!\n",
      "And in a bottle\n",
      "But I like to hold.\n",
      "And then! Oh the things fall!\n",
      "Theyd sing! And theyd SING!\n",
      "Your mother is not!\n",
      "The things that were down.\n",
      "And a little star.\n",
      "Your mother is out!\n",
      "Who sews crows clothes.\n",
      "Not in a puddle\n",
      "No! Not in a boat!\n",
      "with the Goo Goose is doing.\n",
      "All I like to talk.\n",
      "its called a Yink.\n",
      "and that is not all\n",
      "On my hand with a mouse\n",
      "Socks on chicks and tocks sir.\n",
      "mixed up with it now!\n",
      "When our mother like this?\n",
      "Eat them! Eat them! Eat them!\n",
      "The Cat in the rain.\n",
      "That Sam I am.\n",
      "Then those Things yet!\n",
      "They should not be here.\n",
      "So all we could play\n",
      "Not with a goat?\n",
      "Socks on Knox tock.\n",
      "Then he went up hill.\n",
      "Not with a bump\n",
      "He had a hook.\n",
      "Then out of town.\n",
      "They have come to call.\n",
      "That Sam I am Sam\n",
      "All I like to hold.\n",
      "Who sews whose clothes?\n",
      "And the cat said\n",
      "Well we can have\n",
      "Then the Whos feast!\n",
      "HE ME He is wet.\n",
      "That is not all!\n",
      "Just jump on the ball.\n",
      "that Sam I am.\n",
      "We have a dish.\n",
      "And in a box?\n",
      "I sat there we two.\n",
      "And in a house.\n",
      "The Cat in the Hat.\n",
      "Not on a boat?\n",
      "I do!! I like this?\n",
      "You did not like them.\n",
      "Thank you for a mouse.\n",
      "That is what they call\n",
      "And some are blue.\n",
      "Oh the things fall!\n",
      "This is not all.\n",
      "THREE TREE Three fish in the house\n",
      "Bricks and blocks sir.\n",
      "Lets have a dish.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-1bb3f4a01271>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;31m# improve the main function by creating a new file named neural_rap.txt instead of starting with an empty file named neural_rap.txt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-1bb3f4a01271>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(depth, train_mode)\u001b[0m\n\u001b[1;32m    321\u001b[0m                 \u001b[0;31m#print(vectors)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m                 \u001b[0mrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectors_into_song\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhyme_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrap_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mbar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-1bb3f4a01271>\u001b[0m in \u001b[0;36mvectors_into_song\u001b[0;34m(vectors, generated_lyrics, rhyme_list)\u001b[0m\n\u001b[1;32m    272\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscorelist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                         \u001b[0mfixed_score_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m                 \u001b[0mmax_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed_score_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscorelist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "import pronouncing\n",
    "import markovify\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM \n",
    "from keras.layers.core import Dense\n",
    "\n",
    "#os.chdir('/Users/ptm/desktop/cwd20171207')\n",
    "\n",
    "\n",
    "depth = 4 # depth of the network. changing will require a retrain\n",
    "maxsyllables = 8 # maximum syllables per line. Change this freely without retraining the network\n",
    "train_mode = True\n",
    "#artist = \"kanye_west\" # used when saving the trained model\n",
    "#artist = \"lil_wayne\" # used when saving the trained model\n",
    "artist = \"dr_seuss\" # used when saving the trained model\n",
    "\n",
    "\n",
    "rap_file = \"neural_rap.txt\" # where the rap is written to\n",
    "\n",
    "def create_network(depth):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(4, input_shape=(2, 2), return_sequences=True))\n",
    "\tfor i in range(depth):\n",
    "\t\tmodel.add(LSTM(8, return_sequences=True))\n",
    "\tmodel.add(LSTM(2, return_sequences=True))\n",
    "\tmodel.summary()\n",
    "\tmodel.compile(optimizer='rmsprop',\n",
    "              loss='mse')\n",
    "\n",
    "\tif artist + \".rap\" in os.listdir(\".\") and train_mode == False:\n",
    "\t\tmodel.load_weights(str(artist + \".rap\"))\n",
    "\t\tprint(\"loading saved network: \" + str(artist) + \".rap\") \n",
    "\treturn model\n",
    "\n",
    "def markov(text_file):\n",
    "    ######\n",
    "\tread = open(text_file, \"r\", encoding='utf-8').read()\n",
    "\ttext_model = markovify.NewlineText(read)\n",
    "\treturn text_model\n",
    "\n",
    "def syllables(line):\n",
    "\tcount = 0\n",
    "\tfor word in line.split(\" \"):\n",
    "\t\tvowels = 'aeiouy'\n",
    "\t\tword = word.lower().strip(\".:;?!\")\n",
    "\t\tif word[0] in vowels:\n",
    "\t\t\tcount +=1\n",
    "\t\tfor index in range(1,len(word)):\n",
    "\t\t\tif word[index] in vowels and word[index-1] not in vowels:\n",
    "\t\t\t\tcount +=1\n",
    "\t\tif word.endswith('e'):\n",
    "\t\t\tcount -= 1\n",
    "\t\tif word.endswith('le'):\n",
    "\t\t\tcount+=1\n",
    "\t\tif count == 0:\n",
    "\t\t\tcount +=1\n",
    "\treturn count / maxsyllables\n",
    "\n",
    "def rhymeindex(lyrics):\n",
    "\tif str(artist) + \".rhymes\" in os.listdir(\".\") and train_mode == False:\n",
    "\t\tprint (\"loading saved rhymes from \" + str(artist) + \".rhymes\")\n",
    "\t\treturn open(str(artist) + \".rhymes\", \"r\",encoding='utf-8').read().split(\"\\n\")\n",
    "\telse:\n",
    "\t\trhyme_master_list = []\n",
    "\t\tprint (\"Alright, building the list of all the rhymes\")\n",
    "\t\tfor i in lyrics:\n",
    "\t\t\tword = re.sub(r\"\\W+\", '', i.split(\" \")[-1]).lower()\n",
    "\t\t\trhymeslist = pronouncing.rhymes(word)\n",
    "\t\t\trhymeslist = [x.encode('UTF8') for x in rhymeslist]\n",
    "\t\t\trhymeslistends = []\n",
    "\t\t\tfor i in rhymeslist:\n",
    "\t\t\t\trhymeslistends.append(i[-2:])\n",
    "\t\t\ttry:\n",
    "\t\t\t\trhymescheme = max(set(rhymeslistends), key=rhymeslistends.count)\n",
    "\t\t\texcept Exception:\n",
    "\t\t\t\trhymescheme = word[-2:]\n",
    "\t\t\trhyme_master_list.append(rhymescheme)\n",
    "\t\trhyme_master_list = list(set(rhyme_master_list))\n",
    "\n",
    "\t\treverselist = [x[::-1] for x in rhyme_master_list]\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "\t\treverselist = sorted(str(reverselist))\n",
    "\t\t#\n",
    "        #\n",
    "        #\n",
    "\t\trhymelist = [x[::-1] for x in reverselist]\n",
    "\n",
    "\t\tf = open(str(artist) + \".rhymes\", \"w\", encoding='utf-8')\n",
    "\t\tf.write(\"\\n\".join(rhymelist))\n",
    "\t\tf.close()\n",
    "\t\tprint(rhymelist)\n",
    "\t\treturn rhymelist\n",
    "\n",
    "def rhyme(line, rhyme_list):\n",
    "\tword = re.sub(r\"\\W+\", '', line.split(\" \")[-1]).lower()\n",
    "\trhymeslist = pronouncing.rhymes(word)\n",
    "\trhymeslist = [x.encode('UTF8') for x in rhymeslist]\n",
    "\trhymeslistends = []\n",
    "\tfor i in rhymeslist:\n",
    "\t\trhymeslistends.append(i[-2:])\n",
    "\ttry:\n",
    "\t\trhymescheme = max(set(rhymeslistends), key=rhymeslistends.count)\n",
    "\texcept Exception:\n",
    "\t\trhymescheme = word[-2:]\n",
    "\ttry:\n",
    "\t\tfloat_rhyme = rhyme_list.index(rhymescheme)\n",
    "\t\tfloat_rhyme = float_rhyme / float(len(rhyme_list))\n",
    "\t\treturn float_rhyme\n",
    "\texcept Exception:\n",
    "\t\t#return None\n",
    "\t\treturn 0\n",
    "##################\n",
    "def split_lyrics_file(text_file):\n",
    "\ttext = open(text_file, encoding='utf-8').read()\n",
    "\ttext = text.split(\"\\n\")\n",
    "\twhile \"\" in text:\n",
    "\t\ttext.remove(\"\")\n",
    "\treturn text\n",
    "\n",
    "\n",
    "def generate_lyrics(text_model, text_file):\n",
    "\tbars = []\n",
    "\tlast_words = []\n",
    "\tlyriclength = len(open(text_file,encoding='utf-8').read().split(\"\\n\"))\n",
    "\tcount = 0\n",
    "\tmarkov_model = markov(text_file)\n",
    "\t\n",
    "\twhile len(bars) < lyriclength / 9 and count < lyriclength * 2:\n",
    "\t\tbar = markov_model.make_sentence()\n",
    "\n",
    "\t\tif type(bar) != type(None) and syllables(bar) < 1:\n",
    "\t\t\t\n",
    "\t\t\tdef get_last_word(bar):\n",
    "\t\t\t\tlast_word = bar.split(\" \")[-1]\n",
    "\t\t\t\tif last_word[-1] in \"!.?,\":\n",
    "\t\t\t\t\tlast_word = last_word[:-1]\n",
    "\t\t\t\treturn last_word\n",
    "\t\t\t\t\n",
    "\t\t\tlast_word = get_last_word(bar)\n",
    "\t\t\tif bar not in bars and last_words.count(last_word) < 3:\n",
    "\t\t\t\tbars.append(bar)\n",
    "\t\t\t\tlast_words.append(last_word)\n",
    "\t\t\t\tcount += 1\n",
    "\treturn bars\n",
    "\n",
    "def build_dataset(lines, rhyme_list):\n",
    "\tdataset = []\n",
    "\tline_list = []\n",
    "\tfor line in lines:\n",
    "\t\tline_list = [line, syllables(line), rhyme(line, rhyme_list)]\n",
    "\t\tdataset.append(line_list)\n",
    "\t\n",
    "\tx_data = []\n",
    "\ty_data = []\n",
    "\t\n",
    "\tfor i in range(len(dataset) - 3):\n",
    "\t\tline1 = dataset[i    ][1:]\n",
    "\t\tline2 = dataset[i + 1][1:]\n",
    "\t\tline3 = dataset[i + 2][1:]\n",
    "\t\tline4 = dataset[i + 3][1:]\n",
    "\n",
    "\t\tx = [line1[0], line1[1], line2[0], line2[1]]\n",
    "\t\tx = np.array(x)\n",
    "\t\tx = x.reshape(2,2)\n",
    "\t\tx_data.append(x)\n",
    "\n",
    "\t\ty = [line3[0], line3[1], line4[0], line4[1]]\n",
    "\t\ty = np.array(y)\n",
    "\t\ty = y.reshape(2,2)\n",
    "\t\ty_data.append(y)\n",
    "\t\t\n",
    "\tx_data = np.array(x_data)\n",
    "\ty_data = np.array(y_data)\n",
    "\t\n",
    "\t#print \"x shape \" + str(x_data.shape)\n",
    "\t#print \"y shape \" + str(y_data.shape)\n",
    "\treturn x_data, y_data\n",
    "\t\n",
    "def compose_rap(lines, rhyme_list, lyrics_file, model):\n",
    "\trap_vectors = []\n",
    "\thuman_lyrics = split_lyrics_file(lyrics_file)\n",
    "\t\n",
    "\tinitial_index = random.choice(range(len(human_lyrics) - 1))\n",
    "\tinitial_lines = human_lyrics[initial_index:initial_index + 2]\n",
    "\t\n",
    "\tstarting_input = []\n",
    "\tfor line in initial_lines:\n",
    "\t\tstarting_input.append([syllables(line), rhyme(line, rhyme_list)])\n",
    "\n",
    "\tstarting_vectors = model.predict(np.array([starting_input]).flatten().reshape(1, 2, 2))\n",
    "\trap_vectors.append(starting_vectors)\n",
    "\t\n",
    "\tfor i in range(100):\n",
    "\t\trap_vectors.append(model.predict(np.array([rap_vectors[-1]]).flatten().reshape(1, 2, 2)))\n",
    "\t\n",
    "\treturn rap_vectors\n",
    "\t\n",
    "def vectors_into_song(vectors, generated_lyrics, rhyme_list):\n",
    "\tprint (\"\\n\\n\")\t\n",
    "\tprint (\"About to write rap (this could take a moment)...\")\n",
    "\tprint (\"\\n\\n\")\n",
    "\tdef last_word_compare(rap, line2):\n",
    "\t\tpenalty = 0 \n",
    "\t\tfor line1 in rap:\n",
    "\t\t\tword1 = line1.split(\" \")[-1]\n",
    "\t\t\tword2 = line2.split(\" \")[-1]\n",
    "\t\t\t \n",
    "\t\t\twhile word1[-1] in \"?!,. \":\n",
    "\t\t\t\tword1 = word1[:-1]\n",
    "\t\t\t\n",
    "\t\t\twhile word2[-1] in \"?!,. \":\n",
    "\t\t\t\tword2 = word2[:-1]\n",
    "\t\t\t\n",
    "\t\t\tif word1 == word2:\n",
    "\t\t\t\tpenalty += 0.2\n",
    "\t\t\t\t\n",
    "\t\treturn penalty\n",
    "\n",
    "\tdef calculate_score(vector_half, syllables, rhyme, penalty):\n",
    "\t\tdesired_syllables = vector_half[0]\n",
    "\t\tdesired_rhyme = vector_half[1]\n",
    "\t\tdesired_syllables = desired_syllables * maxsyllables\n",
    "\t\tdesired_rhyme = desired_rhyme * len(rhyme_list)\n",
    "#\t\tprint(vectors)\n",
    "#\t\tprint(rhyme_list)             \n",
    "#\t\tprint(vector_half)  \n",
    "#\t\tprint(vector_half[0])     \n",
    "#\t\tprint(vector_half[0])         \n",
    "#\t\tprint(desired_rhyme)\t\n",
    "#\t\tprint(desired_syllables)\t\t\n",
    "\t\t#score = 1.0 - abs(((float(desired_syllables) - float(syllables))) + abs((float(desired_rhyme) - float(rhyme)))) - penalty\n",
    "#\t\tscore = 1.0 - abs(desired_syllables - syllables) + abs(desired_rhyme - rhyme) - penalty\n",
    "\t\tscore = 1.0 - abs(float(desired_syllables) - float(syllables)) + abs(float(desired_rhyme) - float(rhyme)) - penalty\n",
    "        \t\t\n",
    "\t\treturn score\n",
    "\t\t\n",
    "\tdataset = []\n",
    "\tfor line in generated_lyrics:\n",
    "\t\tline_list = [line, syllables(line), rhyme(line, rhyme_list)]\n",
    "\t\tdataset.append(line_list)\n",
    "\t\n",
    "\trap = []\n",
    "\t\n",
    "\tvector_halves = []\n",
    "\t\n",
    "\tfor vector in vectors:\n",
    "\t\tvector_halves.append(list(vector[0][0])) \n",
    "\t\tvector_halves.append(list(vector[0][1]))\n",
    "\t\n",
    "\t\t\n",
    "\tfor vector in vector_halves:\n",
    "\t\tscorelist = []\n",
    "\t\tfor item in dataset:\n",
    "\t\t\tline = item[0]\n",
    "\t\t\t\n",
    "\t\t\tif len(rap) != 0:\n",
    "\t\t\t\tpenalty = last_word_compare(rap, line)\n",
    "\t\t\telse:\n",
    "\t\t\t\tpenalty = 0\n",
    "\t\t\ttotal_score = calculate_score(vector, item[1], item[2], penalty)\n",
    "\t\t\tscore_entry = [line, total_score]\n",
    "\t\t\tscorelist.append(score_entry)\n",
    "\t\t\n",
    "\t\tfixed_score_list = []\n",
    "\t\tfor score in scorelist:\n",
    "\t\t\tfixed_score_list.append(float(score[1]))\n",
    "\t\tmax_score = max(fixed_score_list)\n",
    "\t\tfor item in scorelist:\n",
    "\t\t\tif item[1] == max_score:\n",
    "\t\t\t\trap.append(item[0])\n",
    "\t\t\t\tprint (str(item[0]))\n",
    "\t\t\t\t\n",
    "\t\t\t\tfor i in dataset:\n",
    "\t\t\t\t\tif item[0] == i[0]:\n",
    "\t\t\t\t\t\tdataset.remove(i)\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\t\tbreak     \n",
    "\treturn rap\n",
    "\n",
    "def train(x_data, y_data, model):\n",
    "\tmodel.fit(np.array(x_data), np.array(y_data),\n",
    "\t\t\t  batch_size=2,\n",
    "\t\t\t  epochs=30,\n",
    "\t\t\t  verbose=1)\n",
    "\tmodel.save_weights(artist + \".rap\")\n",
    "\t\t\t  \n",
    "\n",
    "\n",
    "def main(depth, train_mode):\n",
    "\tmodel = create_network(depth)\n",
    "#\ttext_file = \"lyrics.txt\"\n",
    "#\ttext_file = \"lilwayne_20171208_E.txt\" \n",
    "\ttext_file = \"drseuss_20171208_D.txt\" \n",
    "#\ttext_file = str(text_file, errors='ignore')\n",
    "#\ttext_file = text_file.encode('utf-8').strip()\n",
    "\n",
    "\n",
    "\ttext_model = markov(text_file)\n",
    "\tif train_mode == True:\n",
    "\t\tbars = split_lyrics_file(text_file)\n",
    "\t\n",
    "\tif train_mode == False:\n",
    "\t\tbars = generate_lyrics(text_model, text_file)\n",
    "\t\n",
    "\trhyme_list = rhymeindex(bars)\n",
    "\tif train_mode == True:\n",
    "\t\tx_data, y_data = build_dataset(bars, rhyme_list)\n",
    "\t\ttrain(x_data, y_data, model)\n",
    "\n",
    "\tif train_mode == False:\n",
    "\t\tvectors = compose_rap(bars, rhyme_list, text_file, model)\n",
    "        #\n",
    "        #\n",
    "\t\t#print(vectors) \n",
    "       \n",
    "\t\trap = vectors_into_song(vectors, bars, rhyme_list)\n",
    "\t\tf = open(rap_file, \"w\", encoding='utf-8')\n",
    "\t\tfor bar in rap:\n",
    "\t\t\tf.write(bar)\n",
    "\t\t\tf.write(\"\\n\")\t\n",
    "\t\t\n",
    "main(depth, train_mode)\n",
    "\n",
    "######### \n",
    "\n",
    "train_mode = False\n",
    "\n",
    "\t\t\n",
    "main(depth, train_mode)\n",
    "\n",
    "# improve the main function by creating a new file named neural_rap.txt instead of starting with an empty file named neural_rap.txt\n",
    "\n",
    "\n",
    "##################\n",
    "\n",
    "lyrics = open(\"neural_rap.txt\", encoding='utf-8').read().split(\"\\n\") #this reads lines from a file called 'neural_rap.txt'\n",
    "print(lyrics)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = open(\"lilwayne_20171208_E.txt\", 'r')\n",
    "# book = file.read()\n",
    "\n",
    "\n",
    "# def tokenize():\n",
    "#     if book is not None:\n",
    "#         words = book.lower().split()\n",
    "#         return words\n",
    "#     else:\n",
    "#         return None\n",
    "        \n",
    "\n",
    "# def map_book(tokens):\n",
    "#     hash_map = {}\n",
    "\n",
    "#     if tokens is not None:\n",
    "#         for element in tokens:\n",
    "#             # Remove Punctuation\n",
    "#             word = element.replace(\",\",\"\")\n",
    "#             word = word.replace(\".\",\"\")\n",
    "\n",
    "#             # Word Exist?\n",
    "#             if word in hash_map:\n",
    "#                 hash_map[word] = hash_map[word] + 1\n",
    "#             else:\n",
    "#                 hash_map[word] = 1\n",
    "\n",
    "#         return hash_map\n",
    "#     else:\n",
    "#         return None\n",
    "\n",
    "\n",
    "# # Tokenize the Book\n",
    "# words = tokenize()\n",
    "# word_list = ['cat','hat','sat']\n",
    "\n",
    "# # Create a Hash Map (Dictionary)\n",
    "# map = map_book(words)\n",
    "\n",
    "# # Show Word Information\n",
    "# for word in word_list:\n",
    "#     print('Word: [' + word + '] Frequency: ' + str(map[word]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
