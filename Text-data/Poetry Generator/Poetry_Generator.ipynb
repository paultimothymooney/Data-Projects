{"cells":[{"metadata":{"_uuid":"91d44ede3fcc8bb6241aa8af0ff2e8f6dcebddec","_cell_guid":"c0e8669e-f5e4-4ad6-a9ee-0ca8c507a0f2"},"cell_type":"markdown","source":"**Poetry Generator (RNN Markov)**"},{"metadata":{"_uuid":"faf39c872e17cfb594e79db2423f66bbae677907","_cell_guid":"9c2c8102-4e2a-431c-b66d-fa16df803735"},"cell_type":"markdown","source":"This scipt uses Recurrent Neural Networks and Markov Chains in order to generate new verses in the style of the poems that it is given as input.  The Markovify functions (Markov Chains) are used to build new sentences (based off of word1=>word2 probabilities), while the Keras.LSTM functions (Recurrent Neural Networks) are used to predict the properties of the next line of the poem (e.g. # syllables, rhyme scheme) such that an appropriate new sentence can be selected (from the setences that were generated with Markovify).  This approach is described in the following publications ([Link #1](http://www.emnlp2015.org/proceedings/EMNLP/pdf/EMNLP221.pdf), [Link #2](https://arxiv.org/pdf/1612.03205.pdf)) and many of the functions were adapted from the following script ([Link #3](https://github.com/robbiebarrat/rapping-neural-network/blob/master/model.py)).  Currently this approach does a better job at making sentences that rhyme as opposed to making sentences that are logical and as such it is best used to generate nonsensical rap lyrics similar to this verse by hip-hop artist Riff Raff:\n> Spandex (spandex), I pull up with a lamb text --\n> Too strudel, toaster strudel, ballin' on you poodles --\n> Swish! Two cougars, 40 plus, clutching Rugers --\n> Got 'em running over Jerome Bettis, Versace lettuce --\n> No dieting, Gucci eyelids, I go to sleep, snobby pilots --\n\nHere we will generate new poems using the vocabulary and rhyme structure of both Notorious B.I.G. and Lil Wayne."},{"metadata":{"_uuid":"96bbc92c8f1f5c107406c5685797bac675972ac8","_cell_guid":"2d91cb0d-2f5e-4c27-b4f6-904dd1061b46"},"cell_type":"markdown","source":"Here are the first 1000 characters from the collection of poems by Notorious B.I.G."},{"metadata":{"_uuid":"d84d271d491fdada05d470fa50f51e81dcd3a9b9","_cell_guid":"7f838686-5ab7-4c52-90fe-d1e4cdee3f70","trusted":true,"collapsed":true},"cell_type":"code","source":"artist_file = '../input/notorious-big.txt'\nwith open(artist_file) as f: # The with keyword automatically closes the file when you are done\n    print (f.read(1000))","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"91d5e5b137353b935127a39282e9c08633565ea2","_cell_guid":"35ce563d-1168-4011-b13a-a2e06eb35fee"},"cell_type":"markdown","source":"Here are the first 1000 characters from the collection of poems by Lil Wayne"},{"metadata":{"_uuid":"55df0d7853c057b05076f678b4ffd55af846cfd8","_cell_guid":"e9ba4064-9a16-45ea-9ccb-73cc9bf5b87b","trusted":true,"collapsed":true},"cell_type":"code","source":"artist_file = '../input/Lil_Wayne.txt'\nwith open(artist_file) as f: # The with keyword automatically closes the file when you are done\n    print (f.read(1000))","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"389b6516bb193d507a05b5e95b2254b5777406e1","_cell_guid":"6638869b-e2b5-4170-8782-2f9aa571b0c5"},"cell_type":"markdown","source":"Plot word frequencies for .txt files"},{"metadata":{"_uuid":"53d77d30736cabac04590eeb01d355761c414db6","collapsed":true,"_cell_guid":"ae010950-3d23-47b5-9db3-02f719a98ee5","trusted":true},"cell_type":"code","source":"import numpy as np\nfrom matplotlib import pyplot as plt\n%matplotlib inline\ndef plotWordFrequency(input):\n    f = open(artist_file,'r')\n    words = [x for y in [l.split() for l in f.readlines()] for x in y]\n    data = sorted([(w, words.count(w)) for w in set(words)], key = lambda x:x[1], reverse=True)[:40] \n    most_words = [x[0] for x in data]\n    times_used = [int(x[1]) for x in data]\n    plt.figure(figsize=(20,10))\n    plt.bar(x=sorted(most_words), height=times_used, color = 'grey', edgecolor = 'black',  width=.5)\n    plt.xticks(rotation=45, fontsize=18)\n    plt.yticks(rotation=0, fontsize=18)\n    plt.xlabel('Most Common Words:', fontsize=18)\n    plt.ylabel('Number of Occurences:', fontsize=18)\n    plt.title('Most Commonly Used Words: %s' % (artist_file), fontsize=24)\n    plt.show()","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"4ac04ea080ac88ef3784dd760c786281ac39e1c6","_cell_guid":"5b2658df-00da-493d-ae8e-7b8d7e677ea3","trusted":true,"collapsed":true},"cell_type":"code","source":"artist_file = '../input/notorious-big.txt'\nplotWordFrequency(artist_file)","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"76d336374a4af223b407142c0fb6c960538a4820","_cell_guid":"e493feb7-6590-4132-9782-1fd5f60426d9","trusted":true,"collapsed":true},"cell_type":"code","source":"artist_file = '../input/Lil_Wayne.txt'\nplotWordFrequency(artist_file)","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"a084c36bef6aee2c5d6e043626badaa6ad32980a","collapsed":true,"_cell_guid":"56613a8d-6a15-4fa6-9e30-f22fde41d905"},"cell_type":"markdown","source":"Here we use Recurrent Neural Networks and Markov chains to generate new lyrics in the style of the input text.\nThe Markovify functions (Markov Chains) are used to build new sentences (based off of word1=>word2 probabilities), while the Keras.LSTM functions (Recurrent Neural Networks) are used to predict the properties of the next line of the poem (e.g. # syllables, rhyme scheme), such that an appropriate new sentence can be selected (from the setences that were generated with Markovify)."},{"metadata":{"_uuid":"c5aefefcc679258e6853fbb30148920b5379f9db","_kg_hide-input":true,"_cell_guid":"1aa60ff1-32c7-44e6-a7a0-7c474845dede","trusted":true,"collapsed":true},"cell_type":"code","source":"import pronouncing\nimport markovify\nimport re\nimport random\nimport numpy as np\nimport os\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import LSTM \nfrom keras.layers.core import Dense","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"2d720e9756aeb01b9fe1617848a78fa9e9c85173","_cell_guid":"f9e9ba9f-e65f-45ab-b072-74e827d856df"},"cell_type":"markdown","source":"Recurrent Neural Network (https://keras.io/layers/recurrent/#lstm)"},{"metadata":{"_uuid":"5e712125b3060fb8342007e35069c04bf6914bdf","_kg_hide-input":true,"collapsed":true,"_cell_guid":"386480e5-e472-4a8b-9250-7385c60b95fd","trusted":true},"cell_type":"code","source":"def create_network(depth):\n\tmodel = Sequential()\n\tmodel.add(LSTM(4, input_shape=(2, 2), return_sequences=True))\n\tfor i in range(depth):\n\t\tmodel.add(LSTM(8, return_sequences=True))\n\tmodel.add(LSTM(2, return_sequences=True))\n\tmodel.summary()\n\tmodel.compile(optimizer='rmsprop',\n              loss='mse')\n\tif artist + \".rap\" in os.listdir(\".\") and train_mode == False:\n\t\tmodel.load_weights(str(artist + \".rap\"))\n\t\tprint(\"loading saved network: \" + str(artist) + \".rap\") \n\treturn model","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"9a0714ec8317aaa65ee65a0bbb2383693f71d894","_cell_guid":"8080103e-ad00-46e3-b6a9-f6d6c06dcc23"},"cell_type":"markdown","source":"Markov Chain (https://github.com/jsvine/markovify)"},{"metadata":{"_uuid":"2abd3e85166d7fbd68e1bc05734c0e0f1f8d62c4","_kg_hide-input":true,"collapsed":true,"_cell_guid":"9b18260b-13f0-4784-8ece-d8e011c826af","trusted":true},"cell_type":"code","source":"def markov(text_file):\n    ######\n\tread = open(text_file, \"r\", encoding='utf-8').read()\n\ttext_model = markovify.NewlineText(read)\n\treturn text_model","execution_count":8,"outputs":[]},{"metadata":{"_uuid":"8b0a2eba8487361f041319f77ec6adfa1e71efa4","_cell_guid":"aa91d1a7-5a4c-42c8-b467-8720a7bd0d22"},"cell_type":"markdown","source":"Determine number of syllables in line"},{"metadata":{"_uuid":"42fbe49eb9eb6f5cedbe78738b4d329a250975a1","_kg_hide-input":true,"collapsed":true,"_cell_guid":"2d881bb1-603f-4007-86fa-7af473878381","trusted":true},"cell_type":"code","source":"def syllables(line):\n\tcount = 0\n\tfor word in line.split(\" \"):\n\t\tvowels = 'aeiouy'\n# \t\tword = word.lower().strip(\"!@#$%^&*()_+-={}[];:,.<>/?\")\n\t\tword = word.lower().strip(\".:;?!\")\n\t\tif word[0] in vowels:\n\t\t\tcount +=1\n\t\tfor index in range(1,len(word)):\n\t\t\tif word[index] in vowels and word[index-1] not in vowels:\n\t\t\t\tcount +=1\n\t\tif word.endswith('e'):\n\t\t\tcount -= 1\n\t\tif word.endswith('le'):\n\t\t\tcount+=1\n\t\tif count == 0:\n\t\t\tcount +=1\n\treturn count / maxsyllables","execution_count":9,"outputs":[]},{"metadata":{"_uuid":"981856a14b03a731f4d20a3707a14a7c6ba7ac20","_cell_guid":"9e7a6b5e-e7b7-4ba5-ac9b-d062ea134893"},"cell_type":"markdown","source":"Make index of words that rhyme with your word"},{"metadata":{"_uuid":"7ebffca980270093ec33d0732ae850a68ac447e1","_kg_hide-input":true,"collapsed":true,"_cell_guid":"4f2c4ad5-fb3d-4271-b4a2-18dbb2caa23a","trusted":true},"cell_type":"code","source":"def rhymeindex(lyrics):\n\tif str(artist) + \".rhymes\" in os.listdir(\".\") and train_mode == False:\n\t\tprint (\"loading saved rhymes from \" + str(artist) + \".rhymes\")\n\t\treturn open(str(artist) + \".rhymes\", \"r\",encoding='utf-8').read().split(\"\\n\")\n\telse:\n\t\trhyme_master_list = []\n\t\tprint (\"Building list of rhymes:\")\n\t\tfor i in lyrics:\n\t\t\tword = re.sub(r\"\\W+\", '', i.split(\" \")[-1]).lower()\n\t\t\trhymeslist = pronouncing.rhymes(word)\n\t\t\trhymeslistends = []      \n\t\t\tfor i in rhymeslist:\n\t\t\t\trhymeslistends.append(i[-2:])\n\t\t\ttry:\n\t\t\t\trhymescheme = max(set(rhymeslistends), key=rhymeslistends.count)\n\t\t\texcept Exception:\n\t\t\t\trhymescheme = word[-2:]\n\t\t\trhyme_master_list.append(rhymescheme)\n\t\trhyme_master_list = list(set(rhyme_master_list))\n\t\treverselist = [x[::-1] for x in rhyme_master_list]\n\t\treverselist = sorted(reverselist)\n\t\trhymelist = [x[::-1] for x in reverselist]\n\t\tprint(\"List of Sorted 2-Letter Rhyme Ends:\")\n\t\tprint(rhymelist)\n\t\tf = open(str(artist) + \".rhymes\", \"w\", encoding='utf-8')\n\t\tf.write(\"\\n\".join(rhymelist))\n\t\tf.close()\n\t\treturn rhymelist","execution_count":10,"outputs":[]},{"metadata":{"_uuid":"5bb75cd9853a6bff67c335fc77ed97d71a6fcee1","_cell_guid":"19d3ad80-3462-404d-8736-aeae4904a257"},"cell_type":"markdown","source":"Make index of rhymes that you use"},{"metadata":{"_uuid":"65976368f90f9d66319f4976f46f5eb4fa2643af","_kg_hide-input":true,"collapsed":true,"_cell_guid":"92c592b0-dc9d-49de-8cae-c0d2fd046cbf","trusted":true},"cell_type":"code","source":"def rhyme(line, rhyme_list):\n\tword = re.sub(r\"\\W+\", '', line.split(\" \")[-1]).lower()\n\trhymeslist = pronouncing.rhymes(word)\n\trhymeslistends = []\n\tfor i in rhymeslist:\n\t\trhymeslistends.append(i[-2:])\n\ttry:\n\t\trhymescheme = max(set(rhymeslistends), key=rhymeslistends.count)\n\texcept Exception:\n\t\trhymescheme = word[-2:]\n\ttry:\n\t\tfloat_rhyme = rhyme_list.index(rhymescheme)\n\t\tfloat_rhyme = float_rhyme / float(len(rhyme_list))\n\t\treturn float_rhyme\n\texcept Exception:\n\t\tfloat_rhyme = None\n\t\treturn float_rhyme","execution_count":11,"outputs":[]},{"metadata":{"_uuid":"f4460c2037b7c9b075f43aa0f08956feaeacef37","collapsed":true,"_cell_guid":"952f9c24-e17c-40e8-8daa-da56ef3f1d55"},"cell_type":"markdown","source":"Separate each line of the input txt"},{"metadata":{"_uuid":"8f9aff708cec94b1b914b2eb5376c3828cb865e9","_kg_hide-input":true,"collapsed":true,"_cell_guid":"9775cd71-d90a-4c25-9beb-d9b5b231a5a3","trusted":true},"cell_type":"code","source":"def split_lyrics_file(text_file):\n\ttext = open(text_file, encoding='utf-8').read()\n\ttext = text.split(\"\\n\")\n\twhile \"\" in text:\n\t\ttext.remove(\"\")\n\treturn text","execution_count":12,"outputs":[]},{"metadata":{"_uuid":"3b35fa5a970df8bc05ff8a62e48fedba19809ec6","_cell_guid":"fd2080fe-0646-4ec3-8d3f-734ef61810fe"},"cell_type":"markdown","source":"Generate lyrics"},{"metadata":{"_uuid":"044128b9e7e55806912e5d4d82883bc3d9235b69","_kg_hide-input":true,"collapsed":true,"_cell_guid":"fceab529-5f76-4207-9a09-e512b0178f87","trusted":true},"cell_type":"code","source":"def generate_lyrics(text_model, text_file):\n\tbars = []\n\tlast_words = []\n\tlyriclength = len(open(text_file,encoding='utf-8').read().split(\"\\n\"))\n\tcount = 0\n\tmarkov_model = markov(text_file)\n\t\n\twhile len(bars) < lyriclength / 9 and count < lyriclength * 2:\n\t\tbar = markov_model.make_sentence(max_overlap_ratio = .49, tries=100)\n\t\tif type(bar) != type(None) and syllables(bar) < 1:\n\t\t\tdef get_last_word(bar):\n\t\t\t\tlast_word = bar.split(\" \")[-1]\n\t\t\t\tif last_word[-1] in \"!.?,\":\n\t\t\t\t\tlast_word = last_word[:-1]\n\t\t\t\treturn last_word\n\t\t\tlast_word = get_last_word(bar)\n\t\t\tif bar not in bars and last_words.count(last_word) < 3:\n\t\t\t\tbars.append(bar)\n\t\t\t\tlast_words.append(last_word)\n\t\t\t\tcount += 1\n\treturn bars","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"accf899804637648f4548973b344b7d649a30e52","_cell_guid":"0c5eb243-f947-4149-9e1f-b76a196bf7eb"},"cell_type":"markdown","source":"Build dataset"},{"metadata":{"_uuid":"0f238d9edbf87da013a7573077acbeffb670cc49","_kg_hide-input":true,"collapsed":true,"_cell_guid":"e912d06c-9c7a-4d29-801b-33e829270817","trusted":true},"cell_type":"code","source":"def build_dataset(lines, rhyme_list):\n\tdataset = []\n\tline_list = []\n\tfor line in lines:\n\t\tline_list = [line, syllables(line), rhyme(line, rhyme_list)]\n\t\tdataset.append(line_list)\n\tx_data = []\n\ty_data = []\n\tfor i in range(len(dataset) - 3):\n\t\tline1 = dataset[i    ][1:]\n\t\tline2 = dataset[i + 1][1:]\n\t\tline3 = dataset[i + 2][1:]\n\t\tline4 = dataset[i + 3][1:]\n\t\tx = [line1[0], line1[1], line2[0], line2[1]]\n\t\tx = np.array(x)\n\t\tx = x.reshape(2,2)\n\t\tx_data.append(x)\n\t\ty = [line3[0], line3[1], line4[0], line4[1]]\n\t\ty = np.array(y)\n\t\ty = y.reshape(2,2)\n\t\ty_data.append(y)\n\tx_data = np.array(x_data)\n\ty_data = np.array(y_data)\n\treturn x_data, y_data","execution_count":14,"outputs":[]},{"metadata":{"_uuid":"e6aa57551cdd61c529e070a6fdd018c3f08d8d28","_cell_guid":"dca711a2-0dc8-4259-90e0-bb0646504be9"},"cell_type":"markdown","source":"Compose verse"},{"metadata":{"_uuid":"34c86d6b733e754993183e8552dca1ba3b964d9d","_kg_hide-input":true,"collapsed":true,"_cell_guid":"fb01184f-3d6d-456a-9788-e3b46af42816","trusted":true},"cell_type":"code","source":"def compose_rap(lines, rhyme_list, lyrics_file, model):\n\trap_vectors = []\n\thuman_lyrics = split_lyrics_file(lyrics_file)\n\tinitial_index = random.choice(range(len(human_lyrics) - 1))\n\tinitial_lines = human_lyrics[initial_index:initial_index + 2]\n\tstarting_input = []\n\tfor line in initial_lines:\n\t\tstarting_input.append([syllables(line), rhyme(line, rhyme_list)])\n\tstarting_vectors = model.predict(np.array([starting_input]).flatten().reshape(1, 2, 2))\n\trap_vectors.append(starting_vectors)\n\tfor i in range(100):\n\t\trap_vectors.append(model.predict(np.array([rap_vectors[-1]]).flatten().reshape(1, 2, 2)))\n\treturn rap_vectors","execution_count":15,"outputs":[]},{"metadata":{"_uuid":"efff3822d4862abd2b4711d5d92ef308abe4dcfc","_cell_guid":"fbb63119-dd4a-4e1d-b505-ac974be54bc4"},"cell_type":"markdown","source":"Compose verse (part 2)"},{"metadata":{"_uuid":"c78565ee5b673e3447028de35cd199d4f3f5da24","_kg_hide-input":true,"collapsed":true,"_cell_guid":"695ae5a1-a074-4f5f-846a-fe2b4fa6207b","trusted":true},"cell_type":"code","source":"def vectors_into_song(vectors, generated_lyrics, rhyme_list):\n\tprint (\"\\n\\n\")\t\n\tprint (\"Writing verse:\")\n\tprint (\"\\n\\n\")\n\tdef last_word_compare(rap, line2):\n\t\tpenalty = 0 \n\t\tfor line1 in rap:\n\t\t\tword1 = line1.split(\" \")[-1]\n\t\t\tword2 = line2.split(\" \")[-1]\n\t\t\twhile word1[-1] in \"?!,. \":\n\t\t\t\tword1 = word1[:-1]\n\t\t\twhile word2[-1] in \"?!,. \":\n\t\t\t\tword2 = word2[:-1]\n\t\t\tif word1 == word2:\n\t\t\t\tpenalty += 0.2\n\t\treturn penalty\n\tdef calculate_score(vector_half, syllables, rhyme, penalty):\n\t\tdesired_syllables = vector_half[0]\n\t\tdesired_rhyme = vector_half[1]\n\t\tdesired_syllables = desired_syllables * maxsyllables\n\t\tdesired_rhyme = desired_rhyme * len(rhyme_list)\n\t\tscore = 1.0 - abs(float(desired_syllables) - float(syllables)) + abs(float(desired_rhyme) - float(rhyme)) - penalty\n\t\treturn score\n\tdataset = []\n\tfor line in generated_lyrics:\n\t\tline_list = [line, syllables(line), rhyme(line, rhyme_list)]\n\t\tdataset.append(line_list)\n\trap = []\n\tvector_halves = []\n\tfor vector in vectors:\n\t\tvector_halves.append(list(vector[0][0])) \n\t\tvector_halves.append(list(vector[0][1]))\n\tfor vector in vector_halves:\n\t\tscorelist = []\n\t\tfor item in dataset:\n\t\t\tline = item[0]\n\t\t\tif len(rap) != 0:\n\t\t\t\tpenalty = last_word_compare(rap, line)\n\t\t\telse:\n\t\t\t\tpenalty = 0\n\t\t\ttotal_score = calculate_score(vector, item[1], item[2], penalty)\n\t\t\tscore_entry = [line, total_score]\n\t\t\tscorelist.append(score_entry)\n\t\tfixed_score_list = [0]\n\t\tfor score in scorelist:\n\t\t\tfixed_score_list.append(float(score[1]))\n\t\tmax_score = max(fixed_score_list)\n\t\tfor item in scorelist:\n\t\t\tif item[1] == max_score:\n\t\t\t\trap.append(item[0])\n\t\t\t\tprint (str(item[0]))\n\t\t\t\tfor i in dataset:\n\t\t\t\t\tif item[0] == i[0]:\n\t\t\t\t\t\tdataset.remove(i)\n\t\t\t\t\t\tbreak\n\t\t\t\tbreak     \n\treturn rap","execution_count":16,"outputs":[]},{"metadata":{"_uuid":"f4c609aa17e007078e4fb510769dfc0977ca4a3f","_cell_guid":"e36aef66-8e94-48f1-acb5-0837d3af1ea6"},"cell_type":"markdown","source":"Traning function"},{"metadata":{"_uuid":"a7958f571cabc491061193cac166162ab5854aba","_kg_hide-input":true,"collapsed":true,"_cell_guid":"9640e895-2442-4420-a519-dc586ea4aec0","trusted":true},"cell_type":"code","source":"def train(x_data, y_data, model):\n\tmodel.fit(np.array(x_data), np.array(y_data),\n\t\t\t  batch_size=2,\n\t\t\t  epochs=5,\n\t\t\t  verbose=1)\n\tmodel.save_weights(artist + \".rap\")","execution_count":17,"outputs":[]},{"metadata":{"_uuid":"91977741b33df41f93ac7bbdf346c6072b705081","_cell_guid":"253c1ffd-c269-4af5-ac53-d472bcfe929b"},"cell_type":"markdown","source":"Train and run the model"},{"metadata":{"_uuid":"f7e9d8a08c58a62fdecf1097401a5dcdf770617e","_kg_hide-input":true,"collapsed":true,"_cell_guid":"0c9fdfc8-c331-4b3e-bbab-adf2bc706560","trusted":true},"cell_type":"code","source":"def main(depth, train_mode):\n\tmodel = create_network(depth)\n\ttext_model = markov(text_file)\n\tif train_mode == True:\n\t\tbars = split_lyrics_file(text_file)\n\tif train_mode == False:\n\t\tbars = generate_lyrics(text_model, text_file)\n\trhyme_list = rhymeindex(bars)\n\tif train_mode == True:\n\t\tx_data, y_data = build_dataset(bars, rhyme_list)\n\t\ttrain(x_data, y_data, model)\n\tif train_mode == False:\n\t\tvectors = compose_rap(bars, rhyme_list, text_file, model)\n\t\trap = vectors_into_song(vectors, bars, rhyme_list)\n\t\tf = open(rap_file, \"w\", encoding='utf-8')\n\t\tfor bar in rap:\n\t\t\tf.write(bar)\n\t\t\tf.write(\"\\n\")","execution_count":18,"outputs":[]},{"metadata":{"_uuid":"584d3f99dc4362c7f9345b5836b71105badbcc49","_cell_guid":"dfd2dc9a-3442-4bf8-aaaf-d3f51199e96e"},"cell_type":"markdown","source":"Some important parameters to keep in mind are as follows: (1) maxsyllables: max # of syllables per line; (2) max_overlap_ratio: how different the output should be from the original input; (3) tries: how many times to try to build a line that satisifies some parameter; (4) epochs: how many times for the NN to pass over the data.\n\nTo reduce computational complexity, maximize (1) and (2) and minimize (3) and (4).  \nComputational time will increase dramatically when (1) is less than 8 and when (2) is less than 0.5"},{"metadata":{"_uuid":"9186b5d38204fb48614afc8d95d65b93ab926a3b","collapsed":true,"_cell_guid":"2b9102ed-f28e-4a52-a1cf-828022754e26","trusted":true},"cell_type":"code","source":"depth = 4 \nmaxsyllables = 8\nartist = \"artist\"\nrap_file = \"temporary_poem.txt\"","execution_count":19,"outputs":[]},{"metadata":{"_uuid":"27e73b1d4fb401586b9f6b220ca4bac74e479103","_cell_guid":"1a975718-c5c6-4c37-8a64-17ea3b4822a9"},"cell_type":"markdown","source":"Write new lyrics in the style of Notorious B.I.G.."},{"metadata":{"_uuid":"b37ff1371519d0809160b48965fb9d4f217010c2","_cell_guid":"2d5e90c5-4aea-4ce5-b190-517618cab52e","trusted":true,"collapsed":true},"cell_type":"code","source":"maxsyllables = 8\ntext_file = \"../input/notorious-big.txt\"\ntrain_mode = True        \nmain(depth, train_mode)\ntrain_mode = False\nmain(depth, train_mode)","execution_count":20,"outputs":[]},{"metadata":{"_uuid":"a724cf90869e2fcb8183b3eba647b770f531cb22","_cell_guid":"5e669e56-7fae-4f13-a2a2-ef9acc65c8f1"},"cell_type":"markdown","source":"Write new lyrics in the style of Lil Wayne"},{"metadata":{"_uuid":"49ad03dee20b476be037451667edff6dc652caf1","_cell_guid":"e4797ff7-6d77-493a-a5ce-fefea84ce715","trusted":true,"collapsed":true},"cell_type":"code","source":"text_file = \"../input/Lil_Wayne.txt\"\nmaxsyllables = 8\ntrain_mode = True        \nmain(depth, train_mode)\ntrain_mode = False\nmain(depth, train_mode)","execution_count":21,"outputs":[]},{"metadata":{"_uuid":"d04955719fef66f4549dadfa034d4b72239b83ee","_cell_guid":"e869a412-66bc-4e38-929e-a7b07f3a441f"},"cell_type":"markdown","source":"Write new lyrics in the combined style of Notorious B.I.G. and Lil Wayne."},{"metadata":{"_uuid":"119d24ec33fd0b6991540b4d6bcccba51f4b5019","collapsed":true,"_cell_guid":"7d62e40a-a7a7-4a2e-8edb-af9231b0e428","trusted":true},"cell_type":"code","source":"filenames = ['../input/Lil_Wayne.txt', '../input/notorious-big.txt']\nwith open('combined.txt', 'w') as outfile:\n    for fname in filenames:\n        with open(fname) as infile:\n            for line in infile:\n                outfile.write(line)","execution_count":22,"outputs":[]},{"metadata":{"_uuid":"909f64ec77ab2f216f1f2cb339480e10975f9dbe","_cell_guid":"e47cf64f-b4ec-4446-b110-43d0df87b3be","trusted":true,"collapsed":true},"cell_type":"code","source":"#artist_file = '../input/combined.txt'\nartist_file = 'combined.txt'\nplotWordFrequency(artist_file)","execution_count":23,"outputs":[]},{"metadata":{"_uuid":"b98d3e4ebee7c051b85592cd1900daa1f53d6803","_cell_guid":"5c97d10d-b70b-4381-af64-f7f764ec812f","trusted":true,"collapsed":true},"cell_type":"code","source":"maxsyllables = 8\ntext_file = \"combined.txt\"\ntrain_mode = True        \nmain(depth, train_mode)\ntrain_mode = False\nmain(depth, train_mode)","execution_count":24,"outputs":[]},{"metadata":{"_uuid":"38144f0958df0c0385e6ca7bd9d5fa9f9a0cd545","_cell_guid":"11b79735-f393-4331-8499-0641e30afb62"},"cell_type":"markdown","source":"To Do: (1) Add More Pre-Processing Steps; (2) Increase Size of Individual Lyric Files;"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}