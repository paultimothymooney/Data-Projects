{"cells":[{"metadata":{"_uuid":"a3245cf02d3cb95f9f463784800a648b994d336a"},"cell_type":"markdown","source":"**Exploring the Lord of the Rings Dataset**"},{"metadata":{"trusted":true,"_uuid":"9f2c6a3b311d99758d632b231e71590d092c4e26"},"cell_type":"markdown","source":"I have always been a fan of the Lord of the Rings trilogy, so I was pleasently suprised to find a blog post that discussed gender issues in the Lord of the Rings text ([Link #1](https://nycdatascience.com/blog/student-works/journey-to-middle-earth-webscraping-the-lord-of-the-ring/)).  The author of this blog also published a web scraper for scraping the Lord of the Rings data from http://www.ageofthering.com and http://lotr.wikia.com ([Link #2](https://github.com/tianyigu/Lord_of_the_ring_project/blob/master/LOTR_code/lotr_script_scripy/lotr/lotr/spiders/lotr_spider.py), [Link #3](https://github.com/tianyigu/Lord_of_the_ring_project/blob/master/LOTR_code/lotr_demograph_scripy/lotr/spiders/lotr_spider.py)) -- and I found that this dataset was very hard to resist.  I decided to reimplement some of the ideas from this original blogpost except instead of using the [Bokeh]([http://](https://bokeh.pydata.org/en/latest/) plotting library I wanted to recreate some of the same graphs using [Plot.ly](https://plot.ly/python/) instead.  Likewise, I wanted to build a model to try to identify what character was speaking and I wanted to take a stab at making some original insights as well.\n\nThe ageofthering.com dataset consists of a single CSV file where one column describes the character name and the other column is a specific sentence from the entire Lord of the Rings dialog.  The lotr.wikia.com dataset is another CSV file although this file has many different columns that each contain many different null values.\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"*Step 1: Import Python Packages*"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport math\nimport seaborn as sns\nimport re\nimport missingno as msno\nimport os\nfrom pandas import read_csv\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport itertools\nimport graphviz \nimport json\nimport time\nimport gc\nimport nltk\nfrom os import path\nfrom PIL import Image\nimport eli5\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode, iplot\nfrom collections import Counter\nfrom sklearn import model_selection\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold, learning_curve, StratifiedKFold, train_test_split\nfrom sklearn.metrics import confusion_matrix, make_scorer, accuracy_score \nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom wordcloud import WordCloud, STOPWORDS\nfrom collections import defaultdict\nimport keras\nimport keras.backend as K\nfrom keras.layers import Dense, GlobalAveragePooling1D, Embedding\nfrom keras.callbacks import EarlyStopping\nfrom keras.models import Sequential\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.utils import to_categorical\nimport networkx as nx\nimport plotly.plotly as py\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nfrom plotly import tools\nimport plotly.plotly as py\nfrom collections import Counter\nfrom nltk.util import ngrams\nfrom nltk.corpus import stopwords\nfrom IPython.core import display as ICD\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom nltk.sentiment import SentimentAnalyzer \nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.utils import class_weight\nfrom sklearn.model_selection import GridSearchCV, learning_curve\nfrom palettable.colorbrewer.qualitative import Pastel1_7\npd.set_option('display.max_colwidth', -1)\npd.set_option('display.max_rows', None)  \n%matplotlib inline\ninit_notebook_mode(connected=True) # plotly\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a60e5b7f0ad9db610bfc5a154f017c8920113d00"},"cell_type":"markdown","source":"*Step 2: Load and Process Data*"},{"metadata":{"trusted":true,"_uuid":"792de722c6a18f35e9a8156115a2fd1094b99952","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# some functions are adapted from https://github.com/tianyigu/Lord_of_the_ring_project/blob/master/LOTR_code/LOTR_DEMOGRAPH.ipynb\n\ndef cleanData(character):\n    char = script1[script1[\"char\"]==character][\"dialog\"].map(lambda x : x.replace(\" ,\",\"\")).reset_index(drop=True).tolist()\n    return char\n\ndef countTotal(df,groupby,toCount):\n    total = df.groupby([groupby])[toCount].count()\n    total = pd.DataFrame(total)\n    total = total.reset_index().sort_values(toCount,ascending=0)\n    total.reset_index(drop = True)\n    total.columns = [groupby, 'Count']\n    return total\n\ndef countMarried(df, groupby,toCount):\n    married = df.groupby(groupby).count()[toCount]\n    married = pd.DataFrame(married)\n    married = married.reset_index().sort_values(toCount,ascending=0)\n    married.reset_index(drop = True)\n    married.columns = [groupby,'Count']\n    return married\n\ndef countCharacters(beginSlice,endSlice):\n    counted = int(race2[beginSlice:endSlice]['name'].values) \n    return counted\n\ndef calcMarriage(beginSlice,endSlice):\n    total = int(countTotal(otherData,'race','spouse')[beginSlice:endSlice]['Count'].values)\n    married = int(countMarried(married,'race','spouse')[beginSlice:endSlice]['Count'].values)\n    unmarried = total - married\n    return married, unmarried, total\n\ndef grabValue(df,beginSlice,endSlice):\n    count = int(df.iloc[beginSlice:endSlice]['Count'])\n    return count\n\nscriptPath = '../input/lotr_scripts.csv'\ncharacterPath = '../input/lotr_characters.csv'\nscript = pd.read_csv(f\"{scriptPath}\",encoding='utf-8')\notherData = pd.read_csv(f\"{characterPath}\",dtype={2:'str'})\n\nmarried = otherData[~otherData.spouse.isnull()] \nmarried = married[married.spouse != \"None\"] \nmarried = married.reset_index(drop=True) \notherData = otherData.reset_index(drop=True) \n\nscript[\"count\"] = script[\"char\"].map(lambda x: script[\"char\"].tolist().count(x) )\nscript = script.sort_values(\"count\",ascending = False)\nscript1 = script[script[\"count\"]>=22]\norder = script1[\"char\"].unique()\nchar = script1[\"char\"]\nlineCounts = char.value_counts()\nlineCounts = lineCounts.sort_values(ascending = False)[0:50]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"08a52df819b22ce60b4330bb6ad60ccab3ef7786"},"cell_type":"markdown","source":"*Step 3: Visualize Data*"},{"metadata":{"_uuid":"c03feddfcce47d8f39610bc4c902af87935a9a13"},"cell_type":"markdown","source":"We will begin by plotting some bar charts to describe the total number of lines spoken per character.  Frodo and Sam are the two main characters and so, not surprisingly, they have the most lines in the trilogy."},{"metadata":{"trusted":true,"_uuid":"2387e0d3543d3cb58f593a33b9357575a8156abd","_kg_hide-input":true},"cell_type":"code","source":"# Vertical Plot\nresult1 = lineCounts\ntrace1 = go.Bar(\n                x = result1.index,\n                y = result1,\n                name = \"citations\",\n                marker = dict(color = 'rgba(0, 0, 255, 0.8)',\n                             line=dict(color='rgb(0,0,0)',width=1.5)),\n                text = result1.index)\ndata = [trace1]\nlayout = go.Layout(barmode = \"group\",title='Total Number of Lines Per Character', yaxis= dict(title= 'Number of Lines Spoken'))\nfig = go.Figure(data = data, layout = layout)\niplot(fig)\n\n# Horizontal Plot\ntemp = script1['char'].value_counts()\ntrace = go.Bar(y=temp.index[::-1],x=(temp)[::-1],orientation = 'h')\nlayout = go.Layout(title = \"# of Lines per Character\",xaxis=dict(title='# of Lines per Character',tickfont=dict(size=14,)),\n                   yaxis=dict(title='Character',titlefont=dict(size=16),tickfont=dict(size=14)),margin=dict(l=200,))\ndata = [trace]\nfig = go.Figure(data=data, layout=layout)\niplot(fig,filename='basic-bar')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a98991e0a781ea4ffbba0161afbe8521bc169f22"},"cell_type":"markdown","source":"If you break the trilogy down into its three parts you will see that some of the characters are much more important during the beginning of the trilogy (e.g. Gandalf -- who dies) whereas others are much more important towards the end of the trilogy (e.g. Gollum -- who joins the team).  "},{"metadata":{"trusted":true,"_uuid":"cc29efe953dcb97e1653f88d00d25dd031a8400b","_kg_hide-input":true},"cell_type":"code","source":"#gourpby movies and characters\ngrouped = script1.groupby(['char',\"movie\"]).count()\ngrouped.columns = [\"_\".join(x) for x in grouped.columns.ravel()]\ngrouped = grouped.reset_index()\ngrouped = grouped.iloc[:,:3]\ngrouped.columns = [\"char\",\"movie\",\"count\"]\ngrouped.head()\n\n# grouped['char'].unique()\nARAGORN = grouped[0:3] #\nARWEN = grouped[3:6]\nBILBO = grouped[6:8] #\nBOROMIR = grouped[8:10]\nDENETHOR = grouped[10:12]\nELROND = grouped[12:15]\nEOMER = grouped[15:17]\nEOWYN = grouped[17:19]\nFARAMIR = grouped[19:21]\nFRODO = grouped[21:24] #\nGANDALF = grouped[24:27] #\nGIMLI = grouped[27:30]\nGOLLUM = grouped[30:33] #\nGRIMA = grouped[33:35]\nLEGOLAS = grouped[35:38]\nMERRY = grouped[38:41] #\nORC = grouped[41:44]\nPIPPIN = grouped[44:47] #\nSAM = grouped[47:50] #\nSARUMAN = grouped[50:53]\nSMEAGOL = grouped[53:55]\nSOLDIER = grouped[55:57]\nSTRIDER = grouped[57:58]\nTHEODEN = grouped[58:60]\nTREEBEARD = grouped[60:62]\n\ntrace7 = go.Bar(\n                x = ARAGORN.movie,\n                y = ARAGORN['count'],\n                name = \"ARAGORN\",\n                marker = dict(color = 'rgba(32, 64, 32, 0.8)',\n                             line=dict(color='rgb(0,0,0)',width=1.5)),\n                text = ARAGORN.char)\ntrace6 = go.Bar(\n                x = SAM.movie,\n                y = SAM['count'],\n                name = \"SAM\",\n                marker = dict(color = 'rgba(32, 32, 32, 0.8)',\n                             line=dict(color='rgb(0,0,0)',width=1.5)),\n                text = SAM.char)\ntrace5 = go.Bar(\n                x = PIPPIN.movie,\n                y = PIPPIN['count'],\n                name = \"PIPPIN\",\n                marker = dict(color = 'rgba(128, 128, 128, 0.8)',\n                             line=dict(color='rgb(0,0,0)',width=1.5)),\n                text = PIPPIN.char)\ntrace4 = go.Bar(\n                x = MERRY.movie,\n                y = MERRY['count'],\n                name = \"MERRY\",\n                marker = dict(color = 'rgba(255, 255, 0, 0.8)',\n                             line=dict(color='rgb(0,0,0)',width=1.5)),\n                text = MERRY.char)\ntrace3 = go.Bar(\n                x = GOLLUM.movie,\n                y = GOLLUM['count'],\n                name = \"GOLLUM\",\n                marker = dict(color = 'rgba(0, 255, 255, 0.8)',\n                             line=dict(color='rgb(0,0,0)',width=1.5)),\n                text = GOLLUM.char)\ntrace2 = go.Bar(\n                x = GANDALF.movie,\n                y = GANDALF['count'],\n                name = \"GANDALF\",\n                marker = dict(color = 'rgba(0, 0, 255, 0.8)',\n                             line=dict(color='rgb(0,0,0)',width=1.5)),\n                text = GANDALF.char)\ntrace1 = go.Bar(\n                x = FRODO.movie,\n                y = FRODO['count'],\n                name = \"FRODO\",\n                marker = dict(color = 'rgba(0, 128, 0, 0.8)',\n                             line=dict(color='rgb(0,0,0)',width=1.5)),\n                text = FRODO.char)\ntrace0 = go.Bar(\n                x = BILBO.movie,\n                y = BILBO['count'],\n                name = \"BILBO\",\n                marker = dict(color = 'rgba(0, 128, 128, 0.8)',\n                             line=dict(color='rgb(0,0,0)',width=1.5)),\n                text = BILBO.char)\ndata = [trace0,trace1,trace2,trace3,trace4,trace5,trace6,trace7]\nlayout = go.Layout(barmode = \"group\",title='# of Lines Spoken Per Character',yaxis= dict(title= '# of Lines Spoken'))\n\nfig = go.Figure(data = data, layout = layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"686cddbc345f305d7b95bf5f289185ccda57d34c"},"cell_type":"markdown","source":"Here we use the [NLTK.SentimentIntensityAnalyzer() ](https://www.nltk.org/api/nltk.sentiment.html#module-nltk.sentiment.vader)function to analyze the dialog in more detail.  We can also see that Sam is the most negative of the characters -- he is always trying to protect Mr. Frodo and he is very cautious -- wheras Pippen and Merry are very positive (given their more comfortable circumstances)."},{"metadata":{"trusted":true,"_uuid":"ac2e004fecafcf1115cfe8a1bb5407223e8ea591","_kg_hide-input":true},"cell_type":"code","source":"# adapted from https://github.com/tianyigu/Lord_of_the_ring_project/blob/master/LOTR_code/LOTR_DEMOGRAPH.ipynb\n\nFRODO1 = cleanData(\"FRODO\")\nSAM1 = cleanData(\"SAM\")\nGANDALF1 = cleanData(\"GANDALF\")\nARAGORN1 = cleanData(\"ARAGORN\")\nGOLLUM1 = cleanData(\"GOLLUM\")\nSMEAGOL1 = cleanData(\"SMEAGOL\")\nPIPPIN1 = cleanData(\"PIPPIN\")\nMERRY1 = cleanData(\"MERRY\")\nARWEN1 = cleanData(\"ARWEN\")\nORC1 = cleanData(\"ORC\")\n\ncharlist = {\"FRODO\":FRODO1,\"SAM\":SAM1,\"GANDALF\":GANDALF1, \"ARAGORN\": ARAGORN1,\"GOLLUM\": GOLLUM1, \"SMEAGOL\":SMEAGOL1,\"PIPPIN\":PIPPIN1,'MERRY':MERRY1,\"ARWEN\":ARWEN1}\n\ndef sentiment(char):\n    vader = SentimentIntensityAnalyzer()\n    res_dic = [vader.polarity_scores(text) for text in charlist[char]]\n    res_dic = [res_dic[i] for i in range(len(res_dic)) if res_dic[i][\"compound\"]!=0]\n    res_neg = np.mean([res_dic[i]['neg'] for i in range(len(res_dic))])\n    res_pos = np.mean([res_dic[i]['pos'] for i in range(len(res_dic))])\n    res_com = np.mean([res_dic[i]['compound'] for i in range(len(res_dic))])\n    return res_com    \n\n\nFRODO = sentiment('FRODO')\nSAM = sentiment('SAM')\nGANDALF = sentiment('GANDALF')\nARAGORN = sentiment('ARAGORN')\nGOLLUM = sentiment('GOLLUM')\nSMEAGOL = sentiment('SMEAGOL')\nPIPPIN = sentiment('PIPPIN')\nMERRY = sentiment('MERRY')\nARWEN = sentiment('ARWEN')\n\nraw_data = {'Character': ['Frodo', 'Sam', 'Gandalf', 'Aragorn','Gollum','Smeagol','Pippin','Merry','Arwen'], \n        'SentimentScore': [FRODO,SAM,GANDALF,ARAGORN,GOLLUM,SMEAGOL,PIPPIN,MERRY,ARWEN]}\ndf = pd.DataFrame(raw_data)\n\nresult1 = df\ntrace1 = go.Bar(\n                x = result1.Character,\n                y = result1.SentimentScore,\n                name = \"Sentiment Score -- High is Positive & Low is Negative\",\n                marker = dict(color = 'rgba(0, 0, 255, 0.8)',\n                             line=dict(color='rgb(0,0,0)',width=1.5)),\n                text = \"Sentiment Score\")\ndata = [trace1]\nlayout = go.Layout(barmode = \"group\",title='Sentiment Scores for Different Characters in LOTR', yaxis= dict(title= 'Sentiment Score -- High is Positive & Low is Negative'))\nfig = go.Figure(data = data, layout = layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f529eeda11c22794d0c9d8b705f367328a4a1174"},"cell_type":"markdown","source":"Most of the characters in the Lord of the Rings trilogy are married -- including nearly all of the women."},{"metadata":{"trusted":true,"_uuid":"1c0b68fd4c83513b5bf7e8166ea6c2d505b6c378","_kg_hide-input":true},"cell_type":"code","source":"raceData = otherData\nraceData = raceData[~raceData.race.isnull()]\nraceData = raceData.reset_index(drop=True)\nrace = [\"Men\",'Hobbits','Elves','Dwarves','Dragons','Half-elven','Ainur','Orcs']\nrace2 = raceData.groupby([\"gender\",\"race\"])[\"name\"].count()\nrace2 = race2.reset_index()\nrace2 = race2[race2['race'].isin(race)]\nrace2 = race2[0:14]\n\nmarried2 = countMarried(married,'race','spouse')\ntotal = countTotal(otherData,'race','name') \nmenMarriedCount = grabValue(married2,0,1)\nhobbitsMarriedCount = grabValue(married2,1,2)\nelvesMarriedCount = grabValue(married2,2,3)\ndwarvesMarriedCount = grabValue(married2,3,4)\nainurMarriedCount = grabValue(married2,4,5)\nmenTotalCount = grabValue(total,0,1)\nhobbitsTotalCount = grabValue(total,1,2)\nelvesTotalCount = grabValue(total,2,3)\ndwarvesTotalCount = grabValue(total,4,5)\nainurTotalCount = grabValue(total,3,4)\nmenMarriedPercent = (menMarriedCount*100)/menTotalCount\nhobbitsMarriedPercent = (hobbitsMarriedCount*100)/hobbitsTotalCount\nelvesMarriedPercent = (elvesMarriedCount*100)/elvesTotalCount\ndwarvesMarriedPercent = (dwarvesMarriedCount*100)/dwarvesTotalCount\nainurMarriedPercent = (ainurMarriedCount*100)/ainurTotalCount\n\nraw_data = {'Race': ['Men', 'Hobbits','Elves','Dwarves','Ainur'], \n        'PercentMarried': [menMarriedPercent,hobbitsMarriedPercent,elvesMarriedPercent,dwarvesMarriedPercent,ainurMarriedPercent]}\ndf = pd.DataFrame(raw_data)\n\n\nresult1 = df\ntrace1 = go.Bar(\n                x = result1.Race,\n                y = result1.PercentMarried,\n                name = \"Percent Married\",\n                marker = dict(color = 'rgba(0, 0, 255, 0.8)',\n                             line=dict(color='rgb(0,0,0)',width=1.5)),\n                text = \"Percent Married\")\ndata = [trace1]\nlayout = go.Layout(barmode = \"group\",title='Marriage Rates for Different Races in LOTR', yaxis= dict(title= 'Percent of Characters that are Married'))\nfig = go.Figure(data = data, layout = layout)\niplot(fig)\n\n\ntotal1 = countTotal(otherData,'gender','name')\nmarried1 = countMarried(married,'gender','spouse')\nmaleMarriedCount = grabValue(married1,0,1)\nfemaleMarriedCount = grabValue(married1,1,2)\nmaleTotalCount = grabValue(total1,0,1)\nfemaleTotalCount = grabValue(total1,1,2)\nmaleMarriageRate = (maleMarriedCount*100)/maleTotalCount\nfemaleMarriageRate = (femaleMarriedCount*100)/femaleTotalCount\nraw_data = {'Gender': ['Male', 'Female'], \n        'PercentMarried': [maleMarriageRate,femaleMarriageRate]}\ndf = pd.DataFrame(raw_data)\n\nresult1 = df\ntrace1 = go.Bar(\n                x = result1.Gender,\n                y = result1.PercentMarried,\n                name = \"Percent Married\",\n                marker = dict(color = 'rgba(0, 0, 255, 0.8)',\n                             line=dict(color='rgb(0,0,0)',width=1.5)),\n                text = \"Percent Married\")\ndata = [trace1]\nlayout = go.Layout(barmode = \"group\",title='Marriage Rates for Different Genders in LOTR', yaxis= dict(title= 'Percent of Characters that are Married'))\nfig = go.Figure(data = data, layout = layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"62df03272a163f5c29039c65b10ca355dc983895"},"cell_type":"markdown","source":"Despite most of the characters being married there are astonishingly few women in the Lord of the Rings trilogy."},{"metadata":{"trusted":true,"_uuid":"8dfcc527d5f7eb5a7a0a74d1ce790d79cfca13a4","_kg_hide-input":true},"cell_type":"code","source":"menCountM = countCharacters(12,13)\nhobbitsCountM = countCharacters(11,12)\nelvesCountM = countCharacters(9,10)\ndwarvesCountM = countCharacters(8,9)\nainurCountM = countCharacters(6,7)\nhalfelvenCountM = countCharacters(10,11)\norcsCountM = countCharacters(13,14)\ndragonsCountM = countCharacters(7,8)\nmenCountF = countCharacters(5,6)\nhobbitsCountF = countCharacters(4,5)\nelvesCountF = countCharacters(2,3)\ndwarvesCountF = countCharacters(1,2)\nainurCountF = countCharacters(0,1)\nhalfelvenCountF = countCharacters(3,4)\norcsCountF = 0\ndragonsCountF = 0\n\ngender = [\"Male\",\"Female\"]\nrace = [\"Men\",'Hobbits','Elves','Dwarves','Ainur','Orcs','Half-elven','Dragons']\n\nmale = [menCountM, hobbitsCountM, elvesCountM, dwarvesCountM,ainurCountM, halfelvenCountM, orcsCountM, dragonsCountM]\nfemale = [menCountF, hobbitsCountF, elvesCountF, dwarvesCountM,ainurCountF, halfelvenCountF, orcsCountF, dragonsCountF]\ndata = {'race' : race,\n        'Male'   : male,\n        'Female'   : female}\n\ntrace1 = go.Bar(\n    x=data['race'],\n    y=data['Male'],\n    name='# of Male Characters',\n    marker = dict(color = 'rgba(0, 0, 0, 1)', #0, 0, 255, 0.8\n                             line=dict(color='rgb(0,0,0)',width=1.5))\n)\ntrace2 = go.Bar(\n    x=data['race'],\n    y=data['Female'],\n    name='# of Female Characters',\n    marker = dict(color = 'rgba(255,0,255,1)',\n                             line=dict(color='rgb(0,0,0)',width=1.5))\n)\n\ndata = [trace1, trace2]\nlayout = go.Layout(title='# of Characters per Gender',barmode=\"group\")\n\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"875e18f0d639107e9e36482d7a944dd99784982d"},"cell_type":"markdown","source":"Only around 5% of the dialog in the Lord of the Rings is spoken by women."},{"metadata":{"trusted":true,"_uuid":"a37080e92887993a07ddc6791fe12666a0ae8b41","_kg_hide-input":true,"_kg_hide-output":false},"cell_type":"code","source":"women = ['EOWYN','ARWEN']\nraw_data = {'Gender': ['Male', 'Female'], \n        'Lines': [sum(lineCounts[0:25])-(lineCounts[17]+lineCounts[11]), (lineCounts[17]+lineCounts[11])]}\ndf = pd.DataFrame(raw_data, columns = ['Gender', 'Lines'])\n\nlabels = df.Gender\nvalues = df.Lines\ncolors = [\"#160908\", \"#db1cd4\"]\n\ntrace = go.Pie(labels=labels, values=values,\n               hoverinfo='value', textinfo='label+percent', \n               textfont=dict(size=15),\n               marker=dict(colors=colors, \n                           line=dict(color='#000000', width=2)),)\nlayout = go.Layout(title='Lines Spoken per Gender',\n            annotations = [\n            { \"font\": { \"size\": 20},\n              \"showarrow\": False,\n              \"text\": \"% of Lines Spoken by Each Gender in LOTR\",\n                \"x\": 0.55,\n                \"y\": -.2\n            },])\nfig = go.Figure(data=[trace], layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0ee3c0a57a10e22f52a311d934a298b58065ea55"},"cell_type":"markdown","source":"*Step 4: Build a Model to Identify Speaker*"},{"metadata":{"_uuid":"2f6616ef2f1338a6ac7e0387801d8fe72d73215f"},"cell_type":"markdown","source":"Next I will try to build a model to identify which character is speaking for each given line from the LOTR dialog.\n\nOne informative feature to predict who is speaking might be the most common bi-grams (pairs) or tri-grams of word combinations.\n\nFrodo likes to say \"The Ring\" and \"The Shire\"."},{"metadata":{"trusted":true,"_uuid":"9b063c08fdf1cc5e5457c6f140374f606dd70f30","_kg_hide-input":true},"cell_type":"code","source":"# adapted from https://www.kaggle.com/mamamot/human-intelligible-machine-learning\n\nscript2 = script[['char','dialog']]\n\ndef separateDf(df,column,value):\n    separated = df[column] == value\n    separated = df[separated]\n    return separated\n\nFRODO2 = separateDf(script2,'char',\"FRODO\")\nSAM2 = separateDf(script2,'char',\"SAM\")\nGANDALF2 = separateDf(script2,'char',\"GANDALF\")\nARAGORN2 = separateDf(script2,'char',\"ARAGORN\")\nGOLLUM2 = separateDf(script2,'char',\"GOLLUM\")\nSMEAGOL2 = separateDf(script2,'char',\"SMEAGOL\")\nPIPPIN2 = separateDf(script2,'char',\"PIPPIN\")\nMERRY2 = separateDf(script2,'char',\"MERRY\")\nARWEN2 = separateDf(script2,'char',\"ARWEN\")\nORC2 = separateDf(script2,'char',\"ORC\")\n\nnewdf = pd.concat([FRODO2,SAM2,GANDALF2,ARAGORN2,GOLLUM2,SMEAGOL2,PIPPIN2,MERRY2,ARWEN2,ORC2])\n\ndef preprocess(text):\n    text = text.strip()\n    text = text.replace(\"' \", \" ' \")\n    signs = set(',.:;\"?!')\n    prods = set(text) & signs\n    if not prods:\n        return text\n\n    for sign in prods:\n        text = text.replace(sign, ' {} '.format(sign) )\n    return text\n\na2c = {\"FRODO\":0,\"SAM\":1,\"GANDALF\":2, \"ARAGORN\": 3,\"GOLLUM\": 4, \"SMEAGOL\":5,\"PIPPIN\":6,'MERRY':7,\"ARWEN\":8,\"ORC\":9}\ny = np.array([a2c[a] for a in newdf.char])\ny = to_categorical(y)\ntokenize_regex = re.compile(\"[\\w]+\")\nsw = set(stopwords.words(\"english\"))\n\ndef preprocessText(text, ngram_order):\n    \"\"\"\n    Transform text into a list of ngrams. Feel free to play with the order parameter\n    \"\"\"\n    text = text.lower()\n    \n    text = [\" \".join(ngram) for ngram in ngrams((tokenize_regex.findall(text)), ngram_order) \\\n            if (set(ngram) - sw)] # instead of filtering stopwords, let's just filter out the ngrams\n                                  # with nothing but stopwords\n    return text\n\ndef draw_word_histogram(texts, title, bars=30):\n    \"\"\"\n    Draw a barplot for word frequency distribution.\n    \"\"\"\n    # first, do the counting\n    ngram_counter = Counter()\n    for text in texts:\n        ngram_counter.update(text)\n    # for plotly, we need two lists: xaxis values and the corresponding yaxis values\n    # this is how we split a list of two-element tuples into two lists\n    features, counts = zip(*ngram_counter.most_common(bars))\n    # now let's define the barplot\n    bars = go.Bar(\n        x=counts[::-1],  # inverse the values to have the largest on the top\n        y=features[::-1],\n        orientation=\"h\",  # this makes it a horizontal barplot \n        marker=dict(\n            color='rgb(128, 0, 32)'  # this color is called oxblood... spooky, isn't it?\n        )\n    )\n    # this is how we customize the looks of our barplot\n    layout = go.Layout(\n        paper_bgcolor='rgb(0, 0, 0)',  # color of the background under the title and in the margins\n        plot_bgcolor='rgb(0, 0, 0)',  # color of the plot background\n        title=title,\n        autosize=False,  # otherwise the plot would be too small to contain axis labels\n        width=600,\n        height=800,\n        margin=go.layout.Margin(\n            l=120, # to make space for y-axis labels\n        ),\n        font=dict(\n            family='Serif',\n            size=13, # a lucky number\n            color='rgb(200, 200, 200)'\n        ),\n        xaxis=dict(\n            showgrid=True,  # all the possible lines - try switching them off\n            zeroline=True,\n            showline=True,\n            zerolinecolor='rgb(200, 200, 200)',\n            linecolor='rgb(200, 200, 200)',\n            gridcolor='rgb(200, 200, 200)',\n        ),\n        yaxis=dict(\n            ticklen=8  # to add some space between yaxis labels and the plot\n        )\n        \n    )\n    fig = go.Figure(data=[bars], layout=layout)\n    iplot(fig, filename='h-bar')\n    return\n\nfrodo = newdf[newdf.char==\"FRODO\"].dialog.apply(preprocessText, ngram_order=2)\ndraw_word_histogram(frodo, \"FRODO: Most Common Bi-grams\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9102ff5d9c941bd9b1d50c9094ae6980ebd84503"},"cell_type":"markdown","source":"Wheras Sam likes to say \"Mr Frodo\" and \"come on\"."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"eda0238a67d627919564a05cc10e6e021ee85069"},"cell_type":"code","source":"sam = newdf[newdf.char==\"SAM\"].dialog.apply(preprocessText, ngram_order=2)\ndraw_word_histogram(sam, \"SAM: Most Common Bi-grams\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"13fb7370d2f80bd3d0c4ec1f7150d96e3f1654d5"},"cell_type":"markdown","source":"Frodo often says \"I am sorry\"."},{"metadata":{"trusted":true,"_uuid":"0c3ceec4671806921936fac2a4ffd6772cefde9b","_kg_hide-input":true},"cell_type":"code","source":"frodo = newdf[newdf.char==\"FRODO\"].dialog.apply(preprocessText, ngram_order=3)\ndraw_word_histogram(frodo, \"FRODO: Most Common Tri-grams\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"50db4dc7c28c88dfe8baa49e4590baa3bac3cc12"},"cell_type":"markdown","source":"And Sam often says \"I could carry it\"."},{"metadata":{"trusted":true,"_uuid":"d68d7effb532a51ac93746c027b4cb01930552c5","_kg_hide-input":true},"cell_type":"code","source":"sam = newdf[newdf.char==\"SAM\"].dialog.apply(preprocessText, ngram_order=3)\ndraw_word_histogram(sam, \"SAM: Most Common Tri-grams\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2da47b6af0eb8b68efd0e4a870dfba8b44268b8b"},"cell_type":"markdown","source":"Differences between the most common bi-grams and tri-grams might be informative features to distinguish between characters when building our model."},{"metadata":{"trusted":true,"_uuid":"3e0c1c573b16ec262af1f30d720398eb62806cff","_kg_hide-input":true},"cell_type":"code","source":"# adapted from https://www.kaggle.com/ash316/what-is-the-rock-cooking-ensembling-network\ntrain_df = newdf\ndef generate_ngrams(text, n):\n    words = text.split(' ')\n    iterations = len(words) - n + 1\n    for i in range(iterations):\n       yield words[i:i + n]\ndef net_diagram(*chars):\n    ngrams = {}\n    for title in train_df[train_df.char==chars[0]]['dialog']:\n            for ngram in generate_ngrams(title, 3):\n                ngram = ','.join(ngram)\n                if ngram in ngrams:\n                    ngrams[ngram] += 1\n                else:\n                    ngrams[ngram] = 1\n\n    ngrams_mws_df = pd.DataFrame.from_dict(ngrams, orient='index')\n    ngrams_mws_df.columns = ['count']\n    ngrams_mws_df['char'] = chars[0]\n    ngrams_mws_df.reset_index(level=0, inplace=True)\n\n    ngrams = {}\n    for title in train_df[train_df.char==chars[1]]['dialog']:\n            for ngram in generate_ngrams(title, 3):\n                ngram = ','.join(ngram)\n                if ngram in ngrams:\n                    ngrams[ngram] += 1\n                else:\n                    ngrams[ngram] = 1\n\n    ngrams_mws_df1 = pd.DataFrame.from_dict(ngrams, orient='index')\n    ngrams_mws_df1.columns = ['count']\n    ngrams_mws_df1['char'] = chars[1]\n    ngrams_mws_df1.reset_index(level=0, inplace=True)\n    char1=ngrams_mws_df.sort_values('count',ascending=False)[:25]\n    char2=ngrams_mws_df1.sort_values('count',ascending=False)[:25]\n    df_final=pd.concat([char1,char2])\n    g = nx.from_pandas_edgelist(df_final,source='char',target='index')\n    cmap = plt.cm.RdYlGn\n    colors = [n for n in range(len(g.nodes()))]\n    k = 0.35\n    pos=nx.spring_layout(g, k=k)\n    nx.draw_networkx(g,pos, node_size=df_final['count'].values*8, cmap = cmap, node_color=colors, edge_color='grey', font_size=15, width=3)\n    plt.title(\"Top 25 Shared Trigrams for %s and %s\" %(chars[0],chars[1]), fontsize=30)\n    plt.gcf().set_size_inches(30,30)\n    plt.show()\n    plt.savefig('network.png')\nnet_diagram('FRODO','SAM')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b642cc81c716ac221f07927b77be1735be0189b1"},"cell_type":"markdown","source":"First I will try building a model using [Keras](https://keras.io/)."},{"metadata":{"trusted":true,"_uuid":"1f4fc0f1c505f5008d6ee0cdcb1c5de04c057918","_kg_hide-input":true},"cell_type":"code","source":"# adapted from https://www.kaggle.com/nzw0301/simple-keras-fasttext-val-loss-0-31\ndef create_docs(df, n_gram_max=4):\n    def add_ngram(q, n_gram_max):\n            ngrams = []\n            for n in range(1, n_gram_max+1):\n                for w_index in range(len(q)-n+1):\n                    ngrams.append('--'.join(q[w_index:w_index+n]))\n            return q + ngrams\n        \n    docs = []\n    for doc in df.dialog:\n        doc = preprocess(doc).split()\n        docs.append(' '.join(add_ngram(doc, n_gram_max)))\n    \n    return docs\n\n\nmin_count = 15\ndocs = create_docs(newdf)\ntokenizer = Tokenizer(lower=True, filters='')\ntokenizer.fit_on_texts(docs)\nnum_words = sum([1 for _, v in tokenizer.word_counts.items() if v >= min_count])\ntokenizer = Tokenizer(num_words=num_words, lower=True, filters='')\ntokenizer.fit_on_texts(docs)\ndocs = tokenizer.texts_to_sequences(docs)\nmaxlen = None\ndocs = pad_sequences(sequences=docs, maxlen=maxlen)\ninput_dim = np.max(docs) + 1\nembedding_dims = 20\n\ndef create_model(embedding_dims=20, optimizer='adam'):\n    model = Sequential()\n    model.add(Embedding(input_dim=input_dim, output_dim=embedding_dims))\n    model.add(GlobalAveragePooling1D())\n    model.add(Dense(10, activation='softmax'))\n\n    model.compile(loss='categorical_crossentropy',\n                  optimizer=optimizer,\n                  metrics=['accuracy'])\n    return model\n\nepochs = 20\nx_train, x_test, y_train, y_test = train_test_split(docs, y, test_size=0.2)\n\nmodel = create_model()\nhist = model.fit(x_train, y_train,\n                 batch_size=16,\n                 validation_data=(x_test, y_test),\n                 epochs=epochs,\n                 class_weight=class_weight.compute_class_weight('balanced', np.unique(newdf.char), newdf.char),\n                 callbacks=[EarlyStopping(patience=2, monitor='val_loss')])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6fa810403a0420a1934f38606c5ce3060308f650"},"cell_type":"markdown","source":"That did not work very well.  I think that maybe the dataset is too small or maybe the sentences are too uninteresting and short.\n\nLet's try using scikit-learn's [CountVectorizer](http://scikit-learn.org/dev/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)() and [TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)() instead."},{"metadata":{"trusted":true,"_uuid":"504579c39fdbc5af1c3b5403a41d7e73c47a9d05","_kg_hide-input":true},"cell_type":"code","source":"script2 = script[['char','dialog']]\n\ndef separateDf(df,column,value):\n    separated = df[column] == value\n    separated = df[separated]\n    return separated\n\nFRODO2 = separateDf(script2,'char',\"FRODO\")\nSAM2 = separateDf(script2,'char',\"SAM\")\nGANDALF2 = separateDf(script2,'char',\"GANDALF\")\nARAGORN2 = separateDf(script2,'char',\"ARAGORN\")\nGOLLUM2 = separateDf(script2,'char',\"GOLLUM\")\nSMEAGOL2 = separateDf(script2,'char',\"SMEAGOL\")\nPIPPIN2 = separateDf(script2,'char',\"PIPPIN\")\nMERRY2 = separateDf(script2,'char',\"MERRY\")\nARWEN2 = separateDf(script2,'char',\"ARWEN\")\nORC2 = separateDf(script2,'char',\"ORC\")\n\nnewdf = pd.concat([FRODO2,SAM2,GANDALF2,ARAGORN2,GOLLUM2,SMEAGOL2,PIPPIN2,MERRY2,ARWEN2,ORC2])\n\nX = newdf['dialog']\ny = newdf['char']\n\nvect = CountVectorizer()\nX2 = vect.fit_transform(X)\nX2 = X2.astype('float16') \nlb = LabelEncoder()\ny2 = lb.fit_transform(y)\n\ntfidf = TfidfVectorizer(binary=True)\nX3 = tfidf.fit_transform(X)\nX3 = X3.astype('float16') \nlb = LabelEncoder()\ny3 = lb.fit_transform(y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bc6f9af47ace7080654119696f191d4722af4f3c"},"cell_type":"markdown","source":"With [CountVectorizer](http://scikit-learn.org/dev/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)() we get ~25% accuracy when trying to identify which of 9 different characters."},{"metadata":{"trusted":true,"_uuid":"08e5009725f47325ac49063e857ff43a2203197c","_kg_hide-input":true},"cell_type":"code","source":"# adapted from https://machinelearningmastery.com/compare-machine-learning-algorithms-python-scikit-learn/\ndef compareAccuracy(a, b): \n    print('\\nCompare Multiple Classifiers: \\n')\n    print('K-Fold Cross-Validation Accuracy: \\n')\n    names = []\n    models = []\n    resultsAccuracy = []\n    models.append(('LR', LogisticRegression(class_weight='balanced')))\n    models.append(('LSVM', LinearSVC(class_weight='balanced')))\n    models.append(('RF', RandomForestClassifier(class_weight='balanced')))\n    for name, model in models:\n        model.fit(a, b)\n        kfold = model_selection.KFold(n_splits=10, random_state=7)\n        accuracy_results = model_selection.cross_val_score(model, a,b, cv=kfold, scoring='accuracy')\n        resultsAccuracy.append(accuracy_results)\n        names.append(name)\n        accuracyMessage = \"%s: %f (%f)\" % (name, accuracy_results.mean(), accuracy_results.std())\n        print(accuracyMessage) \n    # Boxplot\n    fig = plt.figure()\n    fig.suptitle('Algorithm Comparison: Accuracy')\n    ax = fig.add_subplot(111)\n    plt.boxplot(resultsAccuracy)\n    ax.set_xticklabels(names)\n    ax.set_ylabel('Cross-Validation: Accuracy Score')\n    plt.show()    \n      \ndef defineModels():\n    print('\\nLR = LogisticRegression')\n    print('LSVM = LinearSVM')\n    print('RF = RandomForestClassifier')    \n    \ncompareAccuracy(X2,y2)\ndefineModels()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b7da4cf8b356f39c2fd7eb30eca6e4c35e7a4f51"},"cell_type":"markdown","source":"We get around 25% accuracy with [TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)() as well."},{"metadata":{"trusted":true,"_uuid":"27f944d23a858121aa154736a62262dbcad0246a","_kg_hide-input":true},"cell_type":"code","source":"compareAccuracy(X3,y3)\ndefineModels()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"9086944458811465dd79c88a3744a69877e57dfd"},"cell_type":"code","source":"def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n    \"\"\"\n    Plots a learning curve. http://scikit-learn.org/stable/modules/learning_curve.html\n    \"\"\"\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n    plt.legend(loc=\"best\")\n    return plt\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    \ndef evaluateRandomForestClassifier(a, b, c, d):\n    model = RandomForestClassifier(class_weight='balanced')\n    model.fit(a, b)\n    kfold = model_selection.KFold(n_splits=10, random_state=7)\n    accuracy = model_selection.cross_val_score(model, a,b, cv=kfold, scoring='accuracy')\n    mean = accuracy.mean() \n    stdev = accuracy.std()\n    print('RandomForestClassifier - Accuracy: %s (%s)' % (mean, stdev),'\\n')\n    prediction = model.predict(c)\n    cnf_matrix = confusion_matrix(d, prediction)\n    np.set_printoptions(precision=2)\n    class_names = dict_characters \n    plt.figure()\n    plot_confusion_matrix(cnf_matrix, classes=class_names,title='Confusion matrix')\n    plt.figure()\n    plot_learning_curve(model, 'Learning Curve For RandomForestClassifier', a, b, (0,1), 10)\n    print('\\n',dict_characters)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"50ea86b61ce36b193de6c904fecf3db7b519fb06"},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X3, y3, test_size=0.2)\ndict_characters = {0: 'Frodo', 1: 'Sam', 2: 'Gandalf', 3:'Aragorn', 4: 'Gollum', 5: 'Smeagol', 6: 'Pippen', 7: 'Merry', 8: 'Arwen'}\nevaluateRandomForestClassifier(X_train, y_train, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a183cc1cfbfff9bf57b4c42f87dbd16f9a143e3"},"cell_type":"markdown","source":"There is a lot that can be done to improve this model.  Maybe one day I will come back and try to improve it.  Hopefully someone in the Kaggle community forks my kernel and makes my model better for me!\n\nMaybe an easier problem would be to identify the gender of the speaker of a given line in the Lord of the Rings text.\n\nWomen in the Lord of the Rings tend to say \"My Lord\" a lot."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"6998dfd5e43862f08ec65f7958d047f5a5e90de5"},"cell_type":"code","source":"script3 = script2\nscript3['gender'] = np.where((script3['char']=='EOWYN') | (script3['char']=='ARWEN'), 'WOMAN', 'MAN')\nlineCounts2 = script3['gender'].value_counts()\nscript4 = script3[['gender','dialog']]\nMAN2 = separateDf(script4,'gender',\"MAN\")\nWOMAN2 = separateDf(script4,'gender',\"WOMAN\")\nnewdf2 = pd.concat([MAN2,WOMAN2])\nnewdf2 = shuffle(newdf2)\n\nmen = script4[script4.gender==\"WOMAN\"].dialog.apply(preprocessText, ngram_order=2)\ndraw_word_histogram(men, \"WOMEN: Most Common Tri-grams\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5bb39de565f5140e26d7a424ba6b96b34844112f"},"cell_type":"markdown","source":"Again I will try building a model using Keras."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"6fe361d22c21890c053292d12e4af4490eaae71a"},"cell_type":"code","source":"newdf2 = newdf2[newdf2['dialog'].notnull()]\na2c = {\"MAN\":0,\"WOMAN\":1}\ndocs = create_docs(newdf2)\n\nmin_count = 15\ndocs = create_docs(newdf2)\ntokenizer = Tokenizer(lower=True, filters='')\ntokenizer.fit_on_texts(docs)\nnum_words = sum([1 for _, v in tokenizer.word_counts.items() if v >= min_count])\ntokenizer = Tokenizer(num_words=num_words, lower=True, filters='')\ntokenizer.fit_on_texts(docs)\ndocs = tokenizer.texts_to_sequences(docs)\nmaxlen = None\ndocs = pad_sequences(sequences=docs, maxlen=maxlen)\ninput_dim = np.max(docs) + 1\nembedding_dims = 20\n\n\ny = np.array([a2c[a] for a in newdf2.gender])\ny = to_categorical(y)\nx_train, x_test, y_train, y_test = train_test_split(docs, y, test_size=0.2)\n\ndef create_model2(embedding_dims=20, optimizer='adam'):\n    model = Sequential()\n    model.add(Embedding(input_dim=input_dim, output_dim=embedding_dims))\n    model.add(GlobalAveragePooling1D())\n    model.add(Dense(2, activation='softmax'))\n\n    model.compile(loss='categorical_crossentropy',\n                  optimizer=optimizer,\n                  metrics=['accuracy'])\n    return model\n\nmodel = create_model2()\nhist = model.fit(x_train, y_train,\n                 batch_size=16,\n                 validation_data=(x_test, y_test),\n                 epochs=epochs,\n                 class_weight=class_weight.compute_class_weight('balanced', np.unique(newdf2.gender), newdf2.gender),\n                 callbacks=[EarlyStopping(patience=2, monitor='val_loss')]\n                )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e34ca4b5dacb18d7d0901180314678e1f8916a47"},"cell_type":"markdown","source":"That seems to have worked reasonably well.  Let's try using scikit-learn's [CountVectorizer](http://scikit-learn.org/dev/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)() and [TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)() now too.\n\nWith [CountVectorizer](http://scikit-learn.org/dev/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)() we get ~90% accuracy when trying to identify the gender of the speaker of each line in the Lord of the Rings text."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"4fdbedb98b3fb4ab960934bf2c790a5b3139b358"},"cell_type":"code","source":"X = newdf2['dialog'].values.astype('U')\ny = newdf2['gender'].values.astype('U')\n\nvect = CountVectorizer()\nX2 = vect.fit_transform(X)\nX2 = X2.astype('float16') \nlb = LabelEncoder()\ny2 = lb.fit_transform(y)\n\ntfidf = TfidfVectorizer(binary=True)\nX3 = tfidf.fit_transform(X)\nX3 = X3.astype('float16') \nlb = LabelEncoder()\ny3 = lb.fit_transform(y)\n\ncompareAccuracy(X2,y2)\ndefineModels()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"71352201efd6134dc1f95c1f706d3c12f03c3bb9"},"cell_type":"markdown","source":"We get around 90% accuracy with [TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)() as well."},{"metadata":{"trusted":true,"_uuid":"8c8e6e1499c0d044d3252e26c448e67888901aa7","_kg_hide-input":true},"cell_type":"code","source":"compareAccuracy(X3,y3)\ndefineModels()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1fbb4b3e7d06d60f0b778886a8e24715594eb337","_kg_hide-input":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X3, y3, test_size=0.2)\ndict_characters= dict_characters = {0: 'MEN', 1: 'WOMEN'}\nevaluateRandomForestClassifier(X_train, y_train, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"312bc2e6e7c4b2199e16dd2232a02c5469b12414"},"cell_type":"markdown","source":"This [RandomForestClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)() seems to work reasonably well."},{"metadata":{"trusted":true,"_uuid":"ab1a618c453f2af3b92aeba84002d3e51d36c83f","_kg_hide-input":true},"cell_type":"code","source":"model = RandomForestClassifier(class_weight='balanced')\nmodel.fit(X3, y3)\nkfold = model_selection.KFold(n_splits=10, random_state=7)\naccuracy_results = model_selection.cross_val_score(model, X3, y3, cv=kfold, scoring='accuracy')\naccuracyMessage = \"%s: %f (%f)\" % (\"RandomForestClassifier\", accuracy_results.mean(), accuracy_results.std())\nprint(accuracyMessage) \neli5.show_prediction(model,doc='X3',vec=vect,targets=y2,top=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8892ff799c914651db918b778e63ce1ec0e79847"},"cell_type":"markdown","source":"There is a lot that can be done to improve these models.  Hopefully someone in the Kaggle community forks my kernel and makes some improvements!\n\nI will plot one last graph as a summary.  Please upvote if you found this helpful!\n"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"02da9a8fa335cc6588321e3f690c4c800f245dd4"},"cell_type":"code","source":"gender = [\"Male\",\"Female\"]\nrace = [\"Men\",'Hobbits','Elves','Dwarves','Ainur','Orcs','Half-elven','Dragons']\n\nmale = [menCountM, hobbitsCountM, elvesCountM, dwarvesCountM,ainurCountM, halfelvenCountM, orcsCountM, dragonsCountM]\nfemale = [menCountF, hobbitsCountF, elvesCountF, dwarvesCountM,ainurCountF, halfelvenCountF, orcsCountF, dragonsCountF]\ndata = {'race' : race,\n        'Male'   : male,\n        'Female'   : female}\n\ntrace1 = go.Bar(\n    x=data['race'],\n    y=data['Male'],\n    name='# of Male Characters',\n    marker = dict(color = 'rgba(0, 0, 0, 1)', #0, 0, 255, 0.8\n                             line=dict(color='rgb(0,0,0)',width=1.5))\n)\ntrace2 = go.Bar(\n    x=data['race'],\n    y=data['Female'],\n    name='# of Female Characters',\n    marker = dict(color = 'rgba(255,0,255,1)',\n                             line=dict(color='rgb(0,0,0)',width=1.5))\n)\n\ndata = [trace1, trace2]\nlayout = go.Layout(title='# of Characters per Gender',barmode=\"group\")\n\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}