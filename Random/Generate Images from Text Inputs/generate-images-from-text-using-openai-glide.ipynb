{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Generate images from text using OpenAI GLIDE","metadata":{}},{"cell_type":"markdown","source":"**GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models**\n - https://github.com/openai/glide-text2im\n - https://arxiv.org/abs/2112.10741\n ","metadata":{}},{"cell_type":"code","source":"!pip install git+https://github.com/openai/glide-text2im","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-01-13T00:43:54.873875Z","iopub.execute_input":"2022-01-13T00:43:54.874269Z","iopub.status.idle":"2022-01-13T00:44:09.740038Z","shell.execute_reply.started":"2022-01-13T00:43:54.874182Z","shell.execute_reply":"2022-01-13T00:44:09.739108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nfrom IPython.display import display\nimport torch as th\n\nfrom glide_text2im.download import load_checkpoint\nfrom glide_text2im.model_creation import (\n    create_model_and_diffusion,\n    model_and_diffusion_defaults,\n    model_and_diffusion_defaults_upsampler\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T00:44:09.743305Z","iopub.execute_input":"2022-01-13T00:44:09.743605Z","iopub.status.idle":"2022-01-13T00:44:11.175046Z","shell.execute_reply.started":"2022-01-13T00:44:09.743565Z","shell.execute_reply":"2022-01-13T00:44:11.174263Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Code adapted from: \n# https://github.com/openai/glide-text2im/blob/main/notebooks/text2im.ipynb\n\n# Sampling parameters\n# Tune upsample_temp to control the sharpness of 256x256 images.\n# A value of 1.0 is sharper, but sometimes results in grainy artifacts.\nupsample_temp = 0.997\nbatch_size = 1\nguidance_scale = 3.0\n\ndef open_ai_glide(text_string_to_generate_image_from):\n    # This notebook supports both CPU and GPU.\n    # On CPU, generating one sample may take on the order of 20 minutes.\n    # On a GPU, it should be under a minute.\n    has_cuda = th.cuda.is_available()\n    device = th.device('cpu' if not has_cuda else 'cuda')\n    # Create base model.\n    options = model_and_diffusion_defaults()\n    options['use_fp16'] = has_cuda\n    options['timestep_respacing'] = '100' # use 100 diffusion steps for fast sampling\n    model, diffusion = create_model_and_diffusion(**options)\n    model.eval()\n    if has_cuda:\n        model.convert_to_fp16()\n    model.to(device)\n    model.load_state_dict(load_checkpoint('base', device))\n    print('total base parameters', sum(x.numel() for x in model.parameters()))\n    # Create upsampler model.\n    options_up = model_and_diffusion_defaults_upsampler()\n    options_up['use_fp16'] = has_cuda\n    options_up['timestep_respacing'] = 'fast27' # use 27 diffusion steps for very fast sampling\n    model_up, diffusion_up = create_model_and_diffusion(**options_up)\n    model_up.eval()\n    if has_cuda:\n        model_up.convert_to_fp16()\n    model_up.to(device)\n    model_up.load_state_dict(load_checkpoint('upsample', device))\n    print('total upsampler parameters', sum(x.numel() for x in model_up.parameters()))\n    def show_images(batch: th.Tensor):\n        \"\"\" Display a batch of images inline. \"\"\"\n        scaled = ((batch + 1)*127.5).round().clamp(0,255).to(th.uint8).cpu()\n        reshaped = scaled.permute(2, 0, 3, 1).reshape([batch.shape[2], -1, 3])\n        display(Image.fromarray(reshaped.numpy()))\n        \n    ##############################\n    # Sample from the base model #\n    ##############################\n\n    # Create the text tokens to feed to the model.\n    tokens = model.tokenizer.encode(prompt)\n    tokens, mask = model.tokenizer.padded_tokens_and_mask(\n        tokens, options['text_ctx']\n    )\n\n    # Create the classifier-free guidance tokens (empty)\n    full_batch_size = batch_size * 2\n    uncond_tokens, uncond_mask = model.tokenizer.padded_tokens_and_mask(\n        [], options['text_ctx']\n    )\n\n    # Pack the tokens together into model kwargs.\n    model_kwargs = dict(\n        tokens=th.tensor(\n            [tokens] * batch_size + [uncond_tokens] * batch_size, device=device\n        ),\n        mask=th.tensor(\n            [mask] * batch_size + [uncond_mask] * batch_size,\n            dtype=th.bool,\n            device=device,\n        ),\n    )\n\n    # Create a classifier-free guidance sampling function\n    def model_fn(x_t, ts, **kwargs):\n        half = x_t[: len(x_t) // 2]\n        combined = th.cat([half, half], dim=0)\n        model_out = model(combined, ts, **kwargs)\n        eps, rest = model_out[:, :3], model_out[:, 3:]\n        cond_eps, uncond_eps = th.split(eps, len(eps) // 2, dim=0)\n        half_eps = uncond_eps + guidance_scale * (cond_eps - uncond_eps)\n        eps = th.cat([half_eps, half_eps], dim=0)\n        return th.cat([eps, rest], dim=1)\n\n    # Sample from the base model.\n    model.del_cache()\n    samples = diffusion.p_sample_loop(\n        model_fn,\n        (full_batch_size, 3, options[\"image_size\"], options[\"image_size\"]),\n        device=device,\n        clip_denoised=True,\n        progress=True,\n        model_kwargs=model_kwargs,\n        cond_fn=None,\n    )[:batch_size]\n    model.del_cache()\n    \n    ##############################\n    # Upsample the 64x64 samples #\n    ##############################\n\n    tokens = model_up.tokenizer.encode(prompt)\n    tokens, mask = model_up.tokenizer.padded_tokens_and_mask(\n        tokens, options_up['text_ctx']\n    )\n\n    # Create the model conditioning dict.\n    model_kwargs = dict(\n        # Low-res image to upsample.\n        low_res=((samples+1)*127.5).round()/127.5 - 1,\n\n        # Text tokens\n        tokens=th.tensor(\n            [tokens] * batch_size, device=device\n        ),\n        mask=th.tensor(\n            [mask] * batch_size,\n            dtype=th.bool,\n            device=device,\n        ),\n    )\n\n    # Sample from the base model.\n    model_up.del_cache()\n    up_shape = (batch_size, 3, options_up[\"image_size\"], options_up[\"image_size\"])\n    up_samples = diffusion_up.ddim_sample_loop(\n        model_up,\n        up_shape,\n        noise=th.randn(up_shape, device=device) * upsample_temp,\n        device=device,\n        clip_denoised=True,\n        progress=True,\n        model_kwargs=model_kwargs,\n        cond_fn=None,\n    )[:batch_size]\n    model_up.del_cache()\n    \n    # Show the output\n    show_images(up_samples)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-13T00:44:11.176511Z","iopub.execute_input":"2022-01-13T00:44:11.176790Z","iopub.status.idle":"2022-01-13T00:44:11.202069Z","shell.execute_reply.started":"2022-01-13T00:44:11.176756Z","shell.execute_reply":"2022-01-13T00:44:11.200207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = \"a hedgehog\"\nopen_ai_glide(prompt)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T00:44:11.204294Z","iopub.execute_input":"2022-01-13T00:44:11.204711Z","iopub.status.idle":"2022-01-13T00:50:03.071195Z","shell.execute_reply.started":"2022-01-13T00:44:11.204673Z","shell.execute_reply":"2022-01-13T00:50:03.070482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = \"an illustration of a hedgehog\"\nopen_ai_glide(prompt)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T00:50:03.072819Z","iopub.execute_input":"2022-01-13T00:50:03.073332Z","iopub.status.idle":"2022-01-13T00:50:31.491088Z","shell.execute_reply.started":"2022-01-13T00:50:03.073295Z","shell.execute_reply":"2022-01-13T00:50:31.490352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = \"a hedgehog using a calculator\"\nopen_ai_glide(prompt)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T00:50:44.562375Z","iopub.execute_input":"2022-01-13T00:50:44.562670Z","iopub.status.idle":"2022-01-13T00:51:12.562824Z","shell.execute_reply.started":"2022-01-13T00:50:44.562630Z","shell.execute_reply":"2022-01-13T00:51:12.561932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = \"a cat\"\nopen_ai_glide(prompt)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T00:51:12.564879Z","iopub.execute_input":"2022-01-13T00:51:12.565149Z","iopub.status.idle":"2022-01-13T00:51:40.584059Z","shell.execute_reply.started":"2022-01-13T00:51:12.565114Z","shell.execute_reply":"2022-01-13T00:51:40.583274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = \"an illustration of a cat\"\nopen_ai_glide(prompt)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-13T00:51:40.585769Z","iopub.execute_input":"2022-01-13T00:51:40.586029Z","iopub.status.idle":"2022-01-13T00:52:08.878826Z","shell.execute_reply.started":"2022-01-13T00:51:40.585996Z","shell.execute_reply":"2022-01-13T00:52:08.877897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = \"a cat using a calculator\"\nopen_ai_glide(prompt)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T00:52:08.881380Z","iopub.execute_input":"2022-01-13T00:52:08.881656Z","iopub.status.idle":"2022-01-13T00:52:37.120260Z","shell.execute_reply.started":"2022-01-13T00:52:08.881607Z","shell.execute_reply":"2022-01-13T00:52:37.119531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = \"a goose\"\nopen_ai_glide(prompt)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T00:52:37.121852Z","iopub.execute_input":"2022-01-13T00:52:37.122285Z","iopub.status.idle":"2022-01-13T00:53:04.734860Z","shell.execute_reply.started":"2022-01-13T00:52:37.122246Z","shell.execute_reply":"2022-01-13T00:53:04.734076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = \"an illustration of a goose\"\nopen_ai_glide(prompt)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T00:53:04.736287Z","iopub.execute_input":"2022-01-13T00:53:04.736604Z","iopub.status.idle":"2022-01-13T00:53:32.425166Z","shell.execute_reply.started":"2022-01-13T00:53:04.736567Z","shell.execute_reply":"2022-01-13T00:53:32.424480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = \"a goose using a calculator\"\nopen_ai_glide(prompt)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T00:53:32.426562Z","iopub.execute_input":"2022-01-13T00:53:32.426990Z","iopub.status.idle":"2022-01-13T00:54:00.252386Z","shell.execute_reply.started":"2022-01-13T00:53:32.426950Z","shell.execute_reply":"2022-01-13T00:54:00.251584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = \"a goose holding a trophy\"\nopen_ai_glide(prompt)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-13T00:54:00.254143Z","iopub.execute_input":"2022-01-13T00:54:00.254401Z","iopub.status.idle":"2022-01-13T00:54:27.943335Z","shell.execute_reply.started":"2022-01-13T00:54:00.254367Z","shell.execute_reply":"2022-01-13T00:54:27.942664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = \"a goose next to a computer\"\nopen_ai_glide(prompt)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T00:54:27.945012Z","iopub.execute_input":"2022-01-13T00:54:27.945277Z","iopub.status.idle":"2022-01-13T00:54:55.597973Z","shell.execute_reply.started":"2022-01-13T00:54:27.945241Z","shell.execute_reply":"2022-01-13T00:54:55.597182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = \"a computer\"\nopen_ai_glide(prompt)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T00:54:55.600592Z","iopub.execute_input":"2022-01-13T00:54:55.600909Z","iopub.status.idle":"2022-01-13T00:55:23.544213Z","shell.execute_reply.started":"2022-01-13T00:54:55.600874Z","shell.execute_reply":"2022-01-13T00:55:23.543491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = \"an oil painting of a computer\"\nopen_ai_glide(prompt)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T00:55:23.545712Z","iopub.execute_input":"2022-01-13T00:55:23.546451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = \"a crayon drawing of a computer\"\nopen_ai_glide(prompt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = \"an illustration of a goose standing next to a computer\"\nopen_ai_glide(prompt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I was really impressed with the images that were included in the paper but when I try my own prompts the results are consistently much worse.","metadata":{}},{"cell_type":"markdown","source":"**GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models**\n - Paper: https://arxiv.org/abs/2112.10741\n - Repo: https://github.com/openai/glide-text2im\n - Code adapted from https://github.com/openai/glide-text2im/blob/main/notebooks/text2im.ipynb\n ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}